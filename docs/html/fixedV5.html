<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <title>OpenSplice DDS Release Notes - Changes and Fixed Bugs V5</title>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
    <link rel="stylesheet" href="../css/prismstyle.css" type="text/css">
  </head>
  <body>
    <p class="back">
      <a href="releasenotes.html">
        Back to Release Notes Page<img src="../images/back.gif" align="middle"
        height="25" width="30" alt="Back">
      </a>
    </p>

    <h1>Fixed Bugs and Changes V5 series</h1>
    <h2>Contents</h2>
    <ul>
      <li><a href="#highlights">Release Highlights</a></li>
      <li><a href="#issues_not_api">Fixed Bugs and Changes not affecting API</a></li>
      <li><a href="#issues_api">Fixed Bugs and Changes affecting API</a></li>
    </ul>
    <hr>
    This page contains a list of all bugfixes and changes incorporated in
    OpenSplice V5.x series of releases<br>

    <h2><a name="highlights">Release Highlights</a></h2>
    <h3>OpenSplice DDS V5.9.1 contains the following new features:</h3>
    <p>
    <ul>
     <li>Adds configurability for data compression in the networking service.
     This allows tuning of the existing (zlib) method, adds two alternative
     fast compressors (lzf and snappy) and provides a plugin api for using
     other mechanisms.</li>
    </ul>
    <h3>OpenSplice DDS V5.9.0 contains the following new features:</h3>
    <p>
    <ul>
     <li>Adds an API-call on the DataReader (for C++ and Java) that allows
     properties to be set for the reader, allowing control over some (runtime)
     properties and specifying other hints to the middleware to optimize
     execution.</li>
     <li>Performance optimisation for Java and C++ DataReaders to allow them to
     specify the number of threads to use when de-marshalling data. Demarshalling
     data to a language-binding specific format can take considerable processing
     depending on the type of the data. Before this change this process was single threaded
     and would therefore limit throughput, especially on multi-core platforms.
     See OSPL-1078 in the API changes section.</li>
   </ul>
    <h3>OpenSplice DDS V5.8.0 contains the following new features:</h3>
    <p>
    <ul>
     <li>Changes to the way read- and take-operations access data. The read- and
     take-operations now provide data circularly, meaning that these operations
     will &apos;resume&apos; a previous read just as if read_next_instance was
     successively called. This way all instances can be read even when for
     example lower key-values get updated between two read-operations with a
     max_samples limit.</li>
   </ul>
    <h3>OpenSplice DDS V5.7.2 contains the following new features:</h3>
    <p>
    <ul>
     <li>Changes to the ReportPlugin facility whereby any invalid entries in any specified ReportPlugin configuration
     or any failure to initialize a specified ReportPlugin will result in OpenSplice DDS failing to start.  An
     appropriate error will be logged to the default error log.</li>
   </ul>
    <h3>OpenSplice DDS V5.7.1 contains the following new features:</h3>
    <p>
    <ul>
     <li>Improved memory manager implementation. This can make significant savings on shared memory usage,
     particularly for large numbers of small messages.</li>
   </ul>
    <h3>OpenSplice DDS V5.7.0 contains the following new features:</h3>
    <p>
    <ul>
     <li>Bug fixes only. Please see <a href="#issues_not_api">Fixed Bugs and Changes not affecting API</a> </li>
   </ul>
    </p>
    <h3>OpenSplice DDS V5.6.0 contains the following new features:</h3>
    <p>
    <ul>
      <li>Customers will benefit from runtime-license-free deployment on Windows,
          Linux and Solaris with the source code being made available under LGPLv3 licensing.
          The commercial 'add-ons' (without source code) are available under the PrismTech Commercial License.
          Optionally, customers can get a full (for all components) PrismTech commercial license for those concerned
          about LGPLv3 licensing.<br>
    </ul>
    </p>
    <h3>OpenSplice DDS V5.5.0 contains the following new features:</h3>
    <p>
    <ul>
      <li>Support for IPV6 for native networking on Windows, Linux and Solaris.<br>
      <li>DDSI2 improvements, including fragmentation for large messages. <a href="ddsi2_release_notes.html">See the DDSI2 release notes for more information.</a><br>
      </li>
      <li>Support for the get_discovered_xxx() APIs</b><br/>
          DomainParticipant; get_discovered_participants(), get_discovered_particpant_data(),
          get_discovered_topics() and get_discovered_topic_data() for C, C++ and Java.</li>
      <li>DDSI1 is now removed from the runtime, but is available as source code. Note: This source
      will be removed when OpenSplice v6 series is released. We recommend any DDSI1 users transition to
      DDSI2.
    </ul>
    </p>
    <h3>OpenSplice DDS V5.4.2 contains the following new features:</h3>
    <p>
    <ul>
      <li>Bounded strings as character array.<br>
         In some use cases a large number of (relatively small) strings may be used in the data
         model and because each string is a reference type, it means that it is not stored inline in
         the datamodel but instead as a pointer. This will result in separate allocations for each
         string (and thus a performance penalty when writing data) and a slight increase in
         memory usage due to pointers and (memory storage) headers for each string.
         The OpenSplice DDS IDL Pre-Processor features a special pragma called stac which
         can be utilized in such use cases. This pragma allows one to indicate that OpenSplice
         DDS should store strings internally as character arrays (but on API level are still bounded
         strings). Because a character array has a fixed size, the pragma stac only effects
         bounded strings. By storing the strings internally as a character array the number of
         allocations is reduced and less memory is used. This is most effective in a scenario
         where a typical string has a relatively small size, e.g. less then 100 characters.<br><br>
         See the IDL Pre-processor user guide for detailed information.
      </li>
      <li>Improved performance for durability using memory mapped persistence by adding multi-threading capability.
         See the reference manual for more information.</li>
     <li>Improved footprint by separation of the key value from a sample. As a
         result only the key value needs to be stored for disposes and
         registrations of an instance. This improves footprint considerably in
         case the key value is just a small part of the entire sample.</li>
    </ul>
    </p>
    <h3>OpenSplice DDS V5.4.1 contains the following new features:</h3>
    <p>
       <ul>
          <li>A brand new beta implementation of DDSI, known now as DDSI2 is now released.
          In this release the old DDSI is still available, but is now deprecated and
          will be removed in the next major/minor release.
          For more information on what DDSI2 supports then see the
          <a href="ddsi2_release_notes.html"> DDSI2 release notes.</a></li>
          <li>Added support for resource_limits.max_instances QoS on a DataWriter</a></li>
          <li>The size of the OpenSplice shared memory database segment size can now be set
          using "friendlier" terms, such as 256M or 2G.</a></li>
          <li>Support for windows hosted VxWorks 6.8 PENTIUM4.</li>
          <li>Support for windows hosted VxWorks 6.7.1 SIMPENTIUM.</li>
          <li>Support for windows and linux hosted VxWorks 6.5 PPC32.</li>
          <li>Support for linux hosted VxWorks 6.5 PPC604.</li>
       </ul>
    </p>
    <h3>OpenSplice DDS V5.4 contains the following new features:</h3>
    <p>
       <ul>
          <li>Robustness added for exhaustion of shared memory. OpenSplice DDS
          will now ensure shared memory does not run out:
          <ul>
             <li>If shared memory is running low then API calls that allocate
             resources (such as write) will return out of resources. Calls that
             do not allocate resources like delete calls or lookup calls are still allowed.
             </li>
             <li>Minimum shared memory size has increased from 1MB to 2MB.
             </li>
             <li>A configurable threshold has been added as a sub element under
             the 'Database' element in the XML Configuration. See the deployment
             manual for more info
             </li>
             <li>Configurable warning levels have been added for all resource limits.
             Once certain warning levels are reached a warning message will be printed
             to the info log. This is to help detection of overzealous resource
             usage by applications.  See the deployment manual (New element is
             called 'ResourceLimits' and can be found under the 'Domain' element)
             for more information.
             </li>
          </ul>
          </li>
          <li>The OpenSplice daemon can now be installed as a Windows service.
          In order to achieve this you must select the following options during
          product installation:
          <ul>
             <li>OpenSplice Installation Scope - All Users</li>
             <li>Global Data Space Sharing - Share Data Between All Users</li>
             <li>Set-up OpenSplice Environment Variables - Yes</li>
             <li>Install the OpenSplice Daemon as a Windows Service - Yes</li>
          </ul>
          <p>The Windows service will run as the user account LocalSystem and be
          configured for automatic start at machine reboot. You can change
          these values using the Windows MMC Administrative Tools Services snap-in.
          The daemon will run the default configured OpenSplice domain. There is an
          issue with log files when running under a windows service. See the
          <a href="knownissues.html">Known Issues</a>
          </p>
          </li>
          <li>The OpenSplice daemon will now clean up invalid processes and temporary files
          on windows when starting to clear problems caused by an unexpected termination
          of the daemon previously.
          </li>
          <li>
          Implementation of new APIs:<br>
          DataWriter; get_matched_subscriptions(), get_matched_subscription_data()
          and get_publication_matched_status()<br>
          DataReader; get_matched_publications(), get_matched_publication_data() and
          get_subscription_matched_status()<br>
          DataWriterListener; on_publication_matched()<br>
          DataReaderListener; on_subscription_matched()
          </li>
         <li>Support for Windows CE 6.0 armv4i platform (32bit)
          </li>
          <li>Secure Networking support for Windows CE 6.0 armv4i platform (32bit)
          </li>
          <li>Support for VxWorks 5.5.1 PENTIUM target hosted on WindowsXP (32bit)
          </li>
          <li>DLRL is now supported on Windows platforms
          </li>
          <li>
          <p>New DDS Examples have been added for enterprise platforms (see the examples directory)
             <ul>
               <li>BuiltInTopics - The BuiltInTopics example is used to illustrate
               the use of built-in topics to obtain and print all nodes running
               in the domain.
               </li>
               <li>ContentFilteredTopic - The StockQuote example is used to
               illustrate message filtering based upon Content-Based subscription.
               </li>
               <li>Durability - The durability example illustrates the ability
               of late joining readers to obtain data that has already been
               published before these readers were created.
               </li>
               <li>HelloWorld - The basic HelloWorld example is used to illustrate
               the necessary steps to setup DCPS entities.
               </li>
               <li>Listener - The HelloWorld_Listener example is used to
               illustrate use of listeners.
               </li>
               <li>Ownership - The ownership example is used to illustrate the
               concept of Shared Ownership, controlled through QoS.
               </li>
               <li>QueryCondition - The StockQuote example is used to illustrate
               message filtering through use of Queries.
               </li>
               <li>WaitSet - The basic HelloWorld_Waitset example is used to
               illustrate the use of waitset and Read, Status, Query and Guard
               conditions.
               </li>
               <li>Lifecycle - The Lifecycle example is used to illustrate the
               different lifecycle states of the sample and the instance.
               </li>
            </ul>
          <p>
          <a href="../../examples/dcps/README.html">See the new examples html for further information</a>
          </p>
          </p>
          </li>
          <li>The src/api/cm/jni component which was part of the commercial source
          code base has been moved to the opensource source code base.
          </li>
          <li>OpenSplice's default network configuration at version 5.3 used ports
              53340, 53350, & 53360. These ports were also used as the default for
              some incompatible OpenSplice 4.x versions. Running incompatible
              versions of OpenSplice on the same ports produced warnings in the
              OpenSplice Info log. To help avoid this situation OpenSplice 5.4
              ships with a default configuration of ports 53370, 53380, & 53390.
          </li>
       </ul>
    </p>
    <h3>OpenSplice DDS V5.3 contains the following new features:</h3>
    <p>
       <ul>
          <li>Merge Policies
          <p>
             So far the OpenSplice DDS durability service was not able to handle
             the so-called "split-brain syndrome". A split-brain syndrome can be
             described as the situation in which two different nodes (possibly)
             have a different perception on (part of) the set of historical
             data. This split-brain occurs when two nodes or two sets of nodes
             (i.e. two systems) that are participating in the same DDS domain
             have been running separately for some time and suddenly get
             connected to each other. Equally this syndrome arises when nodes
             re-connect after being disconnected for some time. Applications on
             these nodes may have been publishing information for the same topic
             in the same partition without this information reaching the other
             party. Therefore their perception on the set of data will be
             different.

             Because of the new emerging environments in which OpenSplice DDS
             is deployed, the durability service has been extended with
             additional functionality to support the alignment of historical
             data when two nodes get connected. Of course, the basic use case
             of a newly started node joining an existing system is supported,
             but in contradiction to that situation there is no universal truth
             in determining who has the best (or the right) information when
             two already running nodes (re)connect.  When this situation
             occurs, the durability service now provides the possibility to
             configure its behaviour in this situation in the form of so-called
             merge policies. The following options are supported:
             <ul>
              <li>Ignore (default)<br/>
              Ignore the situation and take no action at all. This means new
              knowledge is not actively built up. Durability is passive and will
              only build up knowledge that is implicitly received from that
              point forward.</li>
              <li>Delete<br/>
              Delete all historical data by deleting all old knowledge and new
              knowledge is not actively built up. Durability is passive and
              will only build up knowledge that is implicitly received from
              that point forward.</li>
              <li>Replace<br/>
              Replace all historical data by the data set that is available
              on the connecting node.</li>
              <li>Merge<br/>
              Merge the historical data with the data set that is available
              on the connecting node.</li>
            </ul>
          </p>
         </li>
         <li>Real Time System Monitoring (RTSM) - beta for Linux only
          <p>
             The RunTime System Monitor (RTSM) is a commandline tool that allows
             monitoring of metrics and statistics provided by OpenSplice. It can
             show delta's on for example reader-statistics and reset them. The
             tool is currently in a beta-stage and is only delivered with
             Linux-based builds. The tool can be driven through an interactive
             menu, or by passing options/commands through the command line or a
             file.
          </p>
          <p>
             The tool contains explanation of the available options, which can
             be displayed by calling 'rtsm -h'. If you have a domain running
             with the name "OpenSpliceWithStats", where statistics for readers
             are enabled, you can issue the following command: <br><br>
             > rtsm -domain OpenSpliceWithStats -count 5 -readerSort -exit<br><br>
             It will first set the domain to "OpenSpliceWithStats". It will set
             the number of iterations to show statistics to 5, and then run a
             readerSort. When finished it will exit.<br><br>

             The same can be achieved in the interactive mode by calling:<br><br>
             > rtsm <br>
             Then type '4 <RET>' # SETTINGS-menu <br>
             Then type '17 <RET>' # set domain-name <br>
             Then type the domain-name: 'OpenSpliceWithStats <RET>' <br>
             Then type '13 <RET>' # set count <br>
             Then type the count: '5 <RET>' <br>
             Then type '0 <RET>' # back <br>
             Then type '1 <RET>' # show readerSort <br>
             Then, when finished, type '0 <RET>' # exit <br> <br>
             Interactive and commandline-mode can also be combined.
         </p>
         </li>
       </ul>
    </p>
    <p>
       <h3>OpenSplice DDS V5.2.2 contains the following new features:</h3>
       <ul>
          <li>Support for Aonix PERC VM under ElinOS 4.2 on x86 target platform with OpenFusion Real Time ORB Java Edition
          <p>
          When rebuilding the CORBA Java interface, PERC may be used instead of the Sun JDK. Source the percenv.sh script and set SPLICE_JDK=perc
          before running the OpenSplice release.com. This will also cause the example build and run scripts to use PERC.
          </p>
         </li>
       </ul>
    </p>
    <p>
       <h3>OpenSplice DDS V5.2.1 contains the following new features:</h3>
       <ul>
          <li>Support for ElinOS 4.2 on x86 target platform with OpenFusion Real Time ORB Java Edition
         </li>
       </ul>
    </p>
    <p>
      <h3>OpenSplice DDS V5.2.0p1 contains the following new features:</h3>
       <ul>
         <li>Support for linux hosted VxWorks 6.5 PPC745x.
        </li>
       </ul>
    </p>
    <p>
       <h3>OpenSplice DDS V5.2 contains the following new features:</h3>
       <ul>
       <li>Dynamic namespaces
      <p>
      The durability service now has the capability to discover namespaces from other nodes at runtime. This can significantly
      reduce configuration effort in large-scale systems, while also enabling OpenSplice to run in more dynamic environments.
      </p>
         </li>
         <li>Support for Solaris 9 gcc 3.4.2 platform
         </li>
         <li>For C# OpenSplice DDS is now available from the Global Assembly Cache
            <p>
            For C#, there is now a signed and versioned Assembly called dcpssacsAssembly.dll, created from the
            the dcpssacs.dll module, which is added to the Global Assembly cache. In this release,
            as part of the installation, this is added to the global assembly cache.
            </p>
         </li>
         <li>OpenSplice can be configured to allow a single application to operate in multiple domains concurrently
            <p>
             See the OpenSplice Documentation Set for detailed information.
            </p>
         </li>
         <li>Support for coherent updates
            <p>
             Implementation available for the coherent access PRESENTATION QoS policy for INSTANCE (existing)
             and TOPIC (new) access_scopes <br><br>
             See the OpenSplice Documentation Set for detailed information.
            </p>
         </li>
         <li>Now provides a way to dispose all the instances of a topic in one call and to notify the
         receivers in one notification.
            <p>
             This functionality allows an application to dispose of all of the instances
             for a particular topic without the overhead of using an individual
             dispose call for each instance individually. Its effect is equivalent to
             invoking a separate dispose operation for each individual instance
             on the DataWriter that owns it<br<br>
             See the OpenSplice Documentation Set for detailed information.
            </p>
         </li>
       </ul>
    </p>
    <p>
       <h3>OpenSplice DDS V5.1.1 contains the following new features:</h3>
       <ul>
         <li>Support for Windows 7 platform
            <p>
             Added Windows 7 32 bit support with Microsoft Visual Studio 2008.
            </p>
         </li>
         <li>Support for OpenFusion Real Time ORB Java Edition
            <p>
             OpenFusion Real Time ORB Java Edition is now tested with OpenSplice DDS. Additional
             examples have been provided to allow users to get started quickly. In a future release
             documentation updates will be made to the manuals.
            </p>
         </li>
         <li>Symbolic network interface names supported on Window
            <p>
             With Linux or Unix platforms, it is possible to specify the symbolic name
             of a networking interface to be used, like eth0, eth1, wlan0 etc. In this
             release this concept is now supported on Windows using "friendly names",
             which are unique symbolic names tied to each interface.
            </p>
         </li>
       </ul>
    </p>
    <p>
       <h3>OpenSplice DDS V5.1 contains the following new features:</h3>
       <ul>
         <li>Compiled with JAVA6
            <p>
             OpenSplice DDS V5.x is compiled with JDK1.6, but can run on a Java 5 JRE as
             the compile flag -source 1.5 is set
            </p>
         </li>
         <li>Data compression at the network level
            <p>
             OpenSplice DDS can be configured to use zlib compression <a href="http://www.zlib.net/"> www.zlib.net</a>
             to compress network packets. See the OpenSplice Documentation set for further information.
            </p>
         </li>
         <li>Ability to add your own reporting plugin
            <p>
             OpenSplice DDS can be configured to use an external reporting library.
             See the OpenSplice Documentation set for further information.
             This functionality is not available on the embedded platforms (VxWorks or Integrity)
            </p>
         </li>
         <li>Domain identification
            <p>
             A DomainId consists of a string that represents either a URI to the
             location of the configuration file (e.g. 'file:///projects/DDS/ospl.xml') or the
             Domain name as specified in the configuration file. The actual value returned is
             dependent of the value used when creating the DomainParticipant, also see the
             DomainParticipantFactory create_participant operation. If a DomainParticipant
             is created using the Domain name then it will also return the Domain name and
             visa-versa when created using a URI then the URI will be returned by this
             operation. The configuration file, identified by the URI, specifies all
             configuration details of the Domain
            </p>
         </li>
         <li>C# API is now a fully supported API
            <p>
              <a href="csharp.html">View the C# documentation.</a>
            </p>
         </li>
         <li>Allow multiple installations on Windows
            <p>
             In the V4 series OpenSplice DDS used system wide environment variables.
             With OpenSplice DDS V5.1, these are not set. Note: Users will require
             OpenSplice DDS PowerTools 2.3 to cope with this change.
            </p>
         </li>
         <li>Dynamic Discovery
            <p>
            The existing topology-discovery mechanism of OpenSplice's Networking
            Service is extended with a dynamic capability to discover and maintain
            all relevant nodes in large-scale (WAN) systems. In such large-scale
            systems,  static-unicast node pre-definition is not practical nor
            sufficient and dynamic-multicast based discovery is typically not
            supported or even allowed. The new dynamic discovery is based on
            overlaying the physical network with a notion of 'Roles' and 'Scopes'
            that represent 'area-of-interest regions' within the WAN domain such
            that only nodes within the defined scope-of-interest will be
            automatically discovered and their state maintained. In this way,
            the scalability of the dynamic DDS-system is ensured whilst minimizing
            the impact on the overhead of the required discovery process.
            </p>
            <p>
            For more information see the NetworkService elements Role, Discovery,
            Scope and ProbeList in the Deployment Guide.
            </p>
         </li>
       </ul>
    </p>

    <h2><a name="issues_not_api">Fixed Bugs and Changes not affecting existing usage of API</a></h2>
    <p><h3>5.9.1p5</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
       <tr>
         <td>OSPL-1023
         </td>
         <td>
           <b>Service failure actions can be taken multiple times</b><br/>
           <i>
             When multiple services are known to the service framework, a failure
             action can be taken multiple times.
             <br><br>
             <b>Solution: The defect in the service failure action algorithm is 
             now fixed and the action will only be done once.</b>
           </i>
         </td>
       </tr>
        <tr>
          <td>OSPL-1537/<br/>11089<br/>
              OSPL-1966/<br/>11443
          </td>
          <td>
            <b>spliced may crash after a service with the "systemhalt" failure action dies</b><br/>
            <i>
               If a service dies it may not have performed a detach from the 
               OpenSplice kernel/database and so the attached services count may
                be incorrect. That could lead to a crash of a database thread
                because the spliced may get detached too early.
              <br><br>
              <b>Solution: When spliced detects that a service has died, it 
              ensures that attached services count is correctly maintained,
              so such a crash cannot occur.
            </i>
          </td>
        </tr>
    <tr>
       <td>
         OSPL-991/<br/>10735<br/>
         OSPL-1771/<br/> 11395
       </td>
       <td>
         <b>take() and take_w_condition() do not have the same behaviour/random
         crash on take next instance</b><br/>
         <i>
         The dispose_all_data operation on the topic was not treated identically
         to sending a separate dispose message for every entity. This manifested
         itself especially in the way the disposed data was delivered to late
         joiners (which sometimes couldn't see that the data was actually disposed)
         and in the way disposed data ignored the cleanup delay specified on the
         durability service. 
         <br><br>
         <b>Solution: The new implementation of dispose_all_data is much
         more inline with sending separate dispose messages for every instance,
         and thus late joiners will always see the correct instance state.
         Furthermore the dispose messages obey the same cleanup delays as normal
         dispose messages. However, the dispose_all_data function will still be
         me more efficient with respect to the utilization of network network
         bandwitdth, CPU cycles and memory than the manual transmission of
         separate dispose messages.</b>
         </i>
       </td>
       </tr>
    </table>

    <p><h3>5.9.1p4</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1341 / 10914<br><br>OSPL-1930 / 11473
      </td>
      <td>
        <b>The reliable network communication may not operate correctly when the
        first messages of a sending node arrive out of order.</b><br/>
        <i>
          When reconnection is enabled and when the first messages of another
          starting node arrive out of order and also the discovery heartbeats
          arrive later then the first message the reliable network channel will
          not operate correctly.
          <br><br>
          <b>Solution: The notification that a node has become alive by the
          discovery protocol should not reinitialize the reliable channel
          administration associated with that node when the reliable channel
          had already detected that the node was alive.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1923 / 11472
      </td>
      <td>
        <b>Application not detached from shm after deletion of all the
        participants.</b><br/>
        <i>
          When an application creates 2 or more participants and all these
          participants are deleted using the delete_participant function, 
          the application still hold a reference to the shared memory.
          <br><br>
          <b>Solution: The defect is now fixed and when all participants from an
          application are gone the connection to the shared memory is also
          gone.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1936 / 11509
      </td>
      <td>
        <b>Reporting/tracing of networking service could be improved</b><br/>
        <i>
          In case the networking service is configured to allow re-connections,
          it should report when a remote node re-connects. In addition, the
          networking service should also report the channel when reporting a
          missing packet in its trace (if configured) as well as report when and
          if the missing packet is received to be able to find out if
          the service recovered from the missing packet or not.
          <br><br>
          <b>Solution: The reporting and tracing extensions requested above have
          been added to the networking service.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1946 / 11512
      </td>
      <td>
        <b>With compression or encryption enabled lost packets may not be resent</b><br/>
        <i>
          In some situations networking would try to access the compressed
          and/or encrypted content of a packet in its resend-administration,
          causing packets to not be re-transmitted. 
          <br><br>
          <b>Solution: All information needed for (re-)sending of a packet are
          read from the packet-buffer before compression and/or encryption.</b>
        </i>
      </td>
    </tr>
    </table>
    <p><h3>5.9.1p3</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1557/<br>10734
      </td>
      <td>
        <b>Crash of durability during initial alignment</b><br/>
        <i>
          Unregistrations that are aligned by the durability service are stored
          without any data to reduce footprint. These unregistrations can only
          be re-published locally when an instance handle is provided by the
          durability service while doing so. In some scenario's, the durability
          service did not use an instance handle while doing so, which made the
          service crash while locally republishing an aligned unregistration. 
          <br><br>
          <b>Solution: The durability service now ensures an instance handle is
          created in any case while also making sure a registration is created
          in the instance for the writer that originally wrote the aligned
          sample.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1682/<br>11291
      </td>
      <td>
        <b>crash of spliced</b><br/>
        <i>
          In certain scenario's the reader purgeList was doing invalid memory
          reads by trying to access already deleted purgeItems, thereby causing
          potential memory corruption of totally unrelated objects.
          <br><br>
          <b>Solution: The purge algorithm has been modified to prevent this
          situation, thus preventing the memory from becoming corrupted and
          improving the overall stability of the system.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1852<br>
      </td>
      <td>
        <b>Topic disappearance when topic created in parallel</b><br/>
        <i>
          In a scenario where a specific topic was created for the first time in
          the system, but for which a duplicate was created by another application
          before the original could enable its topic, a refCount to the resulting
          topic got dropped and that topic could suddenly disappear while still
          being used by the system. 
          <br><br>
          <b>Solution: A change in the refCounting algorithm has now solved
          this issue.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1867/<br>11443
      </td>
      <td>
        <b>System termination fallback mechanism</b><br/>
        <i>
          When a service crashes and system termination is set into progress,
          a safe system termination is not always guaranteed i.e. the service
          could end up in a deadlock stalling system termination. This is not
          acceptable and the system should always terminate.
          <br><br>
          <b>Solution: A new service termination thread is spawned when the
          system state of a process is set to terminating. This thread waits
          for 5 seconds to see if the process goes from the terminating state
          to the terminated state. If this has not happened after 5 seconds
          the process is being killed by means of _exit.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1882<br>
      </td>
      <td>
        <b>Race condition in parallel demarshalling</b><br/>
        <i>
          When the number of threads used for parallel demarshalling is changed,
          a deadlock condition can occur.
          <br><br>
          <b>Solution: The failing thread synchronization has been fixed.</b>
        </i>
      </td>
    </tr>
    </table>



    <p><h3>5.9.1p2</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1491/<br>8957
      </td>
      <td>
        <b>In the event of an application receiving a SIGSEGV, listener threads
        can spin and write repetitive messages to the ospl-error.log</b><br/>
        <i>
          When the listener is accessing the internal waitset representation of
          its list of events, it was not checking to see whether the waitset failed
          because the DDS database is being detached. That led to the listener
          reporting an error but then continuing in its while loop.
          <br><br>
          <b>Solution: The listener thread now correctly checks the status return
          from the waitset operation and will terminate its while loop in the case
          that it is in a detaching state. This will mean that the listener thread
          will terminate elegantly when a SIGSEGV is received within the application.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1620<br>
      </td>
      <td>
        <b>Generated code crashes when sequences are not set correctly.</b><br/>
        <i>
          When a sequence is set to have a non-zero length, but it's buffer-field
          is not set, the generated code would crash.
          <br><br>
          <b>Solution: The generated code will now verify that for non-zero length
          sequences, an allocated buffer is present.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1669<br>
      </td>
      <td>
        <b>Merged historical data is not delivered to active datareaders.</b><br/>
        <i>
          When configured for merging after re-connecting, the durability service
          does not deliver the aligned samples to existing data-readers. Only newly
          created data-readers from that point forward will get the data. This is
          caused by some internal optimisation mechanism between the transient store
          and existing data-readers. The connection between transient store and existing
          data-readers can be closed in some situation where remote nodes disconnect
          and the durability service does not re-instate this connection when the node reconnects.
          <br><br>
          <b>Solution: The connection between transient store and existing readers
          is now checked and re-instated in case a node reconnects.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1690<br>
      </td>
      <td>
        <b>Memory leakage when reading a topic without keys</b><br/>
        <i>
          With circular read, a bug was introduced which would quickly leak
          large amounts of memory and would hang the process when reading a topic
          without keys.
          <br><br>
          <b>Solution: The memory leak has been fixed.</b>
        </i>
      </td>
    </tr>
    </table>

    <p><h3>5.9.1p1</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1166/<br>10823
      </td>
      <td>
        <b>Terminating the "ospl -f start" operation may not kill all services </b><br/>
        <i>
          The algorithm in ospl that performs the shutdown of the splice daemon
          and its child services in the case of blocking mode did not correctly
          detect whether the splice daemon had been terminated. This meant that
          it was possible that the splice daemon and its services may not necessarily
          have been terminated when "ospl -f start" returns.
          <br><br>
          <b>Solution: The shutdown algorithm in ospl has been improved to correctly
          detect the termination status of the splice daemon in both normal and
          blocking modes.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1172/<br>10827
      </td>
      <td>
        <b>Performance difference between the datareader listener and subscriber listener </b><br/>
        <i>
          In certain scenarios the subscriber listener handling is faster than
          the datareader listener handling.
          <br><br>
          <b>Solution: The handling algorithm of the datareader listener is 
          improved to match the subscriber handling.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1384/<br>10907
      </td>
      <td>
        <b>OpenSplice logs errors when the XML configuration file contains DOCTYPE descriptors</b><br/>
        <i>
          <br><br>
          <b>Solution: The code that logged the errors has been removed.
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1409/<br>10785
      </td>
      <td>
        <b>Durability sometimes reported "No matching policy for nameSpace AutoBuiltinPartition"</b><br/>
        <i>
          The message "No matching policy for nameSpace AutoBuiltinPartition" sometimes
          appeared in the durability logging. This happened because durability
          created a temporary namespace object which had no associated policy.
          Functionally there was no issue, but the log message is confusing.
          <br><br>
          <b>Solution: Durability won't lookup a policy anymore when the
          temporary namespace object is created.
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1478/<br>11042
      </td>
      <td>
        <b>BOUNDS_CHECK does not report the name of the incorrect member when the member is null.</b><br/>
        <i>
          The copyin routines for C and C++ did not check for null-values in string fields. 
          <br><br>
          <b>Solution: Check for null-values in string-fields is added.
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1558
      </td>
      <td>
        <b>Durability sometimes creates conflicting namespace for __BUILT-IN 
        PARTITION__ when partitionTopic is used in namespace-definition.</b><br/>
        <i>
          Durability could automatically create conflicting namespace for
          __BUILT-IN PARTITION__ when partitionTopic is used. 
          <br><br>
          <b>Solution: Durability now only creates a namespace in which the
          builtin-topics are matched, instead of matching the whole
          builtin-partition. 
        </i>
      </td>
    </tr>
    </table>
    <p><h3>5.9.1</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1076/<br>10787
      </td>
      <td>
        <b>Compression in networking is not configurable other than on/off.</b><br/>
        <i>
           Data compression typically involves a trade-off between CPU usage and the amount
           of compression achievable. The utility of the compression feature would be
           increased by allowing more flexibility in terms of this trade-off.
          <br><br>
          <b>Solution: The compression "level" of the existing zlib compressor may now be
          configured. Other compression algorithms may also be used.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1486
      </td>
      <td>
        <b>Java API copy routines were non-optimal for arrays and sequences</b><br/>
        <i>
          The Java copy routines used intermediate copies which were not always necessary.
          <br><br>
          <b>Solution: Copying of arrays and sequences has been changed to do direct
          copies where possible. In case direct copies were not possible due to memory
          layout differences, the specialized copy-routines have been optimized as well,
          providing a considerable performance gain on copy-performance.</b>
        </i>
      </td>
    </tr>
    </table>
    <p><h3>5.9.0</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1509/<br>11063<br>
      </td>
      <td>
        <b>A service generates a trail of defunct processes when the restart FailureAction
        is configured.</b><br/>
        <i>
          In the situation when a service crashes on a posix system and this service is
          configurated with the FailureAction set to restart then a trail of defunct
          processes will be generated of this service.
          <br><br>
          <b>Solution: The fault in the restart mechanism is now fixed
          and will not occur anymore.</b>
        </i>
      </td>
    </tr>
    </table>
    <p><h3>5.8.0p1</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1116/<br>10796<br>
      </td>
      <td>
        <b>When compression is enabled in networking the reliable channel may not operate correctly.</b><br/>
        <i>
          When compression is enabled then the resend messages are incorrect which causes
           the reliable communication to fail.
          <br><br>
          <b>Solution: When sending a compressed message the compressed message and
          the correct message size is now saved on the resend list.</b>
        </i>
      </td>
    </tr>
    </table>
    <p><h3>5.8.0</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-631<br>
      </td>
      <td>
        <b>Using read or take with max_samples limit set can cause some key-values to be never read.</b><br/>
        <i>
          The read and take operations return instances starting with lower key-values.
          If not all available data is read at once (e.g., when having set the
          max_samples limit) and the lower key-values keep receiving updates,
          a subsequently performed read operation will return the updated instances,
          which may prevent the higher key-values to be read.
          <br><br>
          <b>Solution: The read and take operations are changed to provide data circularly
          from a cursor. This means that these operations will 'resume' a read as
          if read_next_instance was succesively called. This way all instances
          can be read even when lower key-values get updated between two
          read-operations with a max_samples limit.</b>
        </i>
      </td>
    </tr>
    </table>
    <p><h3>5.7.5p4</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1148<br>
      </td>
      <td>
        <b>The end_coherent_changes() operation may crash if the publisher contains a
          writer that did not write any samples in that coherent update</b><br/>
        <i>
          There was an issue where calling end_coherent_changes() on a publisher
          may cause a crash if that publisher contained a data writer that had not
          written any samples as part of that coherent update. The algorithm
          assumed that every writer belonging to a coherent publisher would write
          samples within each coherent update.
          <br><br>
          <b>Solution: The algorithm in end_coherent_changes() has been fixed to
            also support data writers that were not active during that coherent update </b>
        </i>
      </td>
    </tr>
    </table>

    <p><h3>5.7.5p3</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>OSPL-1049<br>/107678
      </td>
      <td>
        <b>Java application crash on type register</b><br/>
        <i>
          Randomly, on type register, a java application can crash
          with the following notice: malloc(): memory corruption.
          <br><br>
          <b>Solution: The type register memory allocation algorithm for java
            has been fixed and will no longer crash.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1073<br>/10785
      </td>
      <td>
        <b>Persistency did not function correctly with PartitionTopic elements
        in namespace configuration</b><br/>
        <i>
          When a PartitionTopic element was specified for a namespace, the
          durability persistent store ignored the topic-part of the expression.
          This caused all data to be stored persistently for a partition rather
          than only the specified partition-topic combinations.
          <br><br>
          <b>Solution: An additional filter is added which takes into account
          topics to make sure that only data matched by the expressions as
          specified in the durability namespace configuration will be
          persisted.</b>
        </i>
      </td>
    </tr>
    <tr>
      <td>OSPL-1110<br>/10793
      </td>
      <td>
        <b>Coherent Updates performance issues when re-using instances</b><br/>
        <i>
          When a sample was written to a pre-existing instance of a coherent
          update, it was leading to a decrease in performance on the data reader
          side and eventually possible deadlock, depending on the sample rate.
          <br><br>
          <b>Solution: The algorithm when an end coherent changes marker is received
            at the data reader side has been improved to clear the trigger status
            meaning that inserting a later sample into the instance will not
            necessarily cause a re-evaluation of the query condition. This means
            that samples can be written to the data reader's queue at a consistent
            rate.</b>
        </i>
      </td>
    </tr>
    </table>


    <p><h3>5.7.5p2</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
    <td>OSPL-1013/<br>10750
     </td>
     <td>
       <b>Coherent access with TOPIC presentation not working properly</b><br/>
       <i>
        Applications are not notified of new data when the complete set of
        samples that belong to a transaction have been received when
        using a listener or waitset mechanism. Also, transactions were not
        properly stored in historical data and could therefore not be provided
        to late-joining readers.
        <br><br>
        <b>Solution: The triggering mechanism for waitsets and listeners has
        been adapted to demonstrate correct behaviour concerning notifications
        of end of transactions. Furthermore, the reader plus durability transient and
        persistent store algorithms have been modified to store transactions
        properly.</b>
        </i>
     </td>
    </tr>
    <tr>
    <td>OSPL-1017/<br>10755
     </td>
     <td>
       <b>Durability crashes when alignment data contains only unregister messages</b><br/>
       <i>
        In the scenario where there are only unregister messages aligned by the
        durability service for a given partition-topic combination, the service
        would crash because an instance lookup would fail.
        <br><br>
        <b>Solution: Durability is made robust against this kind of scenario.</b>
        </i>
     </td>
    </tr>
    </table>
    <p><h3>5.7.5p1</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
    <td>OSPL-371/<br>10193
     </td>
     <td>
       <b>The durability 'PartitionTopic' configuration was not correctly communicated.</b><br/>
       <i>
        Because of a bug in the way partition-topic combinations were communicated between
        durability services, communication was sometimes not established because durability
        namespaces did not seem to match.
        <br><br>
        <b>Solution: The durability service now correctly communicates the partition-topics for a namespace.</b>
        </i>
     </td>
    </tr>
    </table>

    <p><h3>5.7.5</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
    <td>OSPL-371/<br>10193
     </td>
     <td>
       <b>Durability needs to support topic granularity in namespace configuration.</b><br/>
       <i>
        In previous versions a user was able to express which partitions belonged to a namespace.
        It appears that there are usecases where a user needs topic-level control here.
        <br><br>
        <b>Solution: Durability now allows specifying partition-topic combinations which allow for
        a finer degree of control. Look for the 'PartitionTopic' element in the Durability/NameSpaces/NameSpace
        configuration.</b>
        </i>
     </td>
    </tr>
    <tr>
    <td>OSPL-706/<br>10272
     </td>
     <td>
       <b>On a failing boundscheck the corresponding member is not reported. </b><br/>
       <i>
        When during a write a member is not in conformance with the bounds specified
        by the type of that member, the middleware reported an error. However, the corresponding
        member was not logged, which makes debugging of these kinds of errors hard.
        <br><br>
        <b>Solution: The member for which the boundscheck fails is now logged. </b>
        </i>
     </td>
    </tr>
    <tr>
    <td>OSPL-892/<br>10091
     </td>
     <td>
       <b>DDSI2 can respond with incorrect set fragments to retransmission requests </b><br/>
       <i>
        The DDSI protocol allows reliable readers to request retransmission of individual fragments
        of large samples. DDSI2 could respond with fragments other than the ones requested, which could
        generally be masked by an eventual request for the full sample to be retransmitted, but would
        cause the communication to come to a complete standstill if a particular fragment always
        got lost. For example, when the rapid (re)transmission of a large amount of data systematically
        lead to a switch throwing away a whole range of packets.
        <br><br>
        <b>Solution: DDSI2 now always responds with the requested fragments.</b>
        </i>
     </td>
    </tr>
    </table>

    <p><h3>5.7.4p11</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>
        OSPL-646
      </td>
      <td>
        <b>Implement Java API performance improvements to reduce JNI boundary crosses</b><br/>
        <i>
          The copy functions that are used to copy data from the shared memory representation
          into their Java language representation and vice-versa were not optimal under all conditions.
          Especially the combination of enums/unions and an external IDL compiler (in CORBA
          cohabitation mode for Java) resulted in additional JNI transitions due to the fact
          that the copy functions had no a-priory knowledge about their actual implementation.
          In these cases the copy functions had to revert to invoking the IDL mandated manipulation
          operations instead directly setting the underlying attributes, and each time a Java
          operation needed to be invoked added the overhead of one additional JNI transition.
          <br><br>
          <b>Solution: The copy functions have now been adapted to use, besides the a-priori
          knowledge about the idlpp output in StandAlone mode, also a-priori knowledge about
          the exact layout for enums/unions generated by the JacORB V2.3.x compiler. Therefore
          there is not need to make additional JNI transitions when manipulating types that
          match one of aforementioned layout, thereby reducing the time required to read and
          write these types. CopyCache administration is now completely separated
          for the a-priory supported IDL layouts (idlpp native output and JacORB V2.3 output)
          and the non-recognized IDL layouts. In the first case it will store jfieldIDs,
          in the latter jmethodIDs. Both layouts now have their own copy functions.</b>
        </i>
      </td>
    </tr>
    </table>
    <p><h3>5.7.4p10</h3></p>
    <table width="90%">
    <tr>
      <th width="14%">
        Report ID.
      </th>
      <th width="86%">
        Description
      </th>
    </tr>
    <tr>
      <td>
        9963/</br>
        dds3426
      </td>
      <td>
        <b>DDSI2 used incorrect encoding for fragment data message headers</b><br/>
        <i>
          DDSI2 incorrectly used to generate and interpret fragmented data
          message headers as if they were slightly extended versions of the
          non-fragmented data message headers. This caused DDSI2 to be
          non-compliant with respect to the standard and to fail to
          interoperate with other vendors' implementations for large samples.
          <br><br>
          <b>Solution: the setting and interpretation has been corrected. This
          breaks backwards compatibility, but because DDSI2 is still in beta,
          this does not constitute a change of policy. For those exceptional
          cases where backwards compatibility is currently an issue, a setting
          Unsupported/LegacyFragmentation has been introduced, which may be set
          to true to continue using and interpreting the old message
          format.</b>
        </i>
      </td>
    </tr>
    </table>
    <p><h3>5.7.4p9</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3525
          </td>
          <td>
            <b>Performance enhancement: Number of select-calls performed by RT-networking reduced</b>
            <i>
            <br><br>
              <b>Solution: The number of select calls performed by RT-networking has been reduced
              when data is received, increasing the performance in many cases.
              Specifically platforms on which selects are expensive and/or deployments where
              multiple networking services share the same NIC (e.g. Solaris Zones) benefit
              from this enhancement.</b>
            </i>
          </td>
        </tr>
      </table>

    <p><h3>5.7.4p8</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            10299 /</br>
            dds3492, dds3500
          </td>
          <td>
            <b>The durability MMF persistency implementation leaks shared memory</b><br/>
            <i>
            The durability service MMF persistency implementation leaked shared memory
            in both the MMF store itself as well as in the 'regular' shared memory on
            the node. Furthermore it synchronised the MMF store to disk during the
            alignment phase unnecessarily.
            <br><br>
              <b>Solution: The memory leaks in the MMF implementation have been resolved and during
             the alignment phase the durability service does not synchronise the data
             to disk any more as it will switch back to the back-up in a consecutive
             run anyway when alignment does not complete successfully.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3501
          </td>
          <td>
            <b>Thread creation hangs when trying to use real-time scheduling without
             appropriate permissions</b><br/>
            <i>
             When OpenSplice is started with a configuration that specifies real-time
             scheduling for one or more threads by a user that does not have operating
             system permissions to start real-time threads,thread creation fails and
             OpenSplice hangs after reporting the error.
              <br><br>
              <b>Solution: OpenSplice now reverts to time-sharing scheduling and continues
              after reporting a warning to indicate missing permissions.</b>
            </i>
          </td>
        </tr>
      </table>

    <p><h3>5.7.4p7</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            10239 /</br>
            dds3261
          </td>
          <td>
            <b>Communication error with VxWorks 6.x</b><br/>
            <i>
             Byte order was reversed, messages were not processed hence
             no communication.
              <br><br>
              <b>Solution: Correct _BYTE_ORDER check used.</b>
            </i>
          </td>
        </tr>        <tr>
          <td>
            10180 /</br>
            dds3418
          </td>
          <td>
            <b>Optimisation for empty Strings in Java</b><br/>
            <i>
              <br><br>
              <b>Solution: The functions used to translate incoming samples into
              the Java language binding have been optimized to handle empty strings.
              These functions used to allocate a separate Java String object for
              each empty string they encountered, but now they will share a single
              and global reference to a default empty String object that has been
              pre-allocated during the start of the Java application. Reusing a
              single empty string object to represent all empty string will reduce
              the overall Java memory footprint and reduce the number of Java object
              allocations, thus reducing execution times as well. This optimization
              will especially benefit applications that communicate large amounts of
              empty strings.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9963 /</br>
            dds3478
          </td>
          <td>
            <b>DDSI2 fragment size is now configurable</b><br/>
            <i>
             DDSI2 never creates data messages containing a payload larger than the
             FragmentSize, any sample larger than the FragmentSize gets split into
             multiple fragments of FragmentSize each. These fragments are then
             transported independently (but may yet be merged into larger UDP datagrams).
              <br><br>
              <b>Solution: This size is now configurable using Unsupported/FragmentSize,
              with a default of 1280 bytes. Values below 1025 bytes violate the DDSI2 specification,
              above approximately 65000 bytes it (probably) won't fit inside a single UDP datagram.
              Increasing the size will shift more fragmenting and reassembling to the IP stack, which
              is generally more efficient because it is done inside the network stack,
              but which is incapable of retransmitting individual lost fragments.
              <b>Increasing it may also allow operating without any fragmenting at the DDSI
              level, which may help avoid interoperability issues.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            10271 /</br>
            dds3474
          </td>
          <td>
            <b>Storage of partition-topic definitions to MMF store takes a long time during alignment</b><br/>
            <i>
             The durability service synchronised the MMF store to disk after storing
             each and every partition-topic definition. Even though this is not
             incorrect, the synchronisation may take a long time, especially in
             a system where a lot of other software is running in parallel. In
             such a situation synchronisation may take up to several minutes.
              <br><br>
              <b>Solution: The durability service now no longer synchronises the
              partition-topic definitions to disk during initial alignment,
              because if not all of them are present, the store cannot be used
              as a source in a consecutive run anyway.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            10270 /</br>
            dds3476
          </td>
          <td>
            <b>SA non root user cannot use Real-Time scheduling</b><br/>
            <i>
             When configuring Real-Time scheduling class for a process or thread,
             they were only applied if the process/thread was started by the
             root user even though other users may have the ability to use the
             Real-Time scheduling classes as well.
              <br><br>
              <b>Solution: The restriction of needing a root user for Real-Time
              scheduling has been removed.</b>
            </i>
          </td>
        </tr>
      </table>

    <p><h3>5.7.4p6</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3217/9881<br>
            dds3430
          </td>
          <td>
            <b>Spliced shared memory leak on remote durability shutdown</b><br/>
            <i>
              A memory leak was found whenever a remote node was started and
              then stopped while durability was also running.
              <br><br>
              <b>Solution: When durability detected a remote node, it would
              write an update into the system (and thus the shared memory on
              the local node). The logic for this write wrongly performed a
              double string creation for the same string. The second string
              creation overwrote the pointer to the first created string, which
              resulted in the first created string to be never freed when the
              remote node disconnected. The solution was to remove the first
              string creation, as it was superfluous. </b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3399/<br>10139
          </td>
          <td>
            <b>Incorrect network statistics.</b><br/>
            <i>
              The networking service optionally keeps track of statistics that
              can be inspected by means of the Tuner tool. After inspection it
              turned out that the maxNumberOfPacketsResentToOneNode and
              maxNumberOfBytesResentToOneNode statistics are showing wrong
              values.
              <br><br>
              <b>Solution: The maxNumberOfPacketsResentToOneNode and
              maxNumberOfBytesResentToOneNode statistics are now showing the
              correct values.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3420/<br>10187
          </td>
          <td>
            <b>Applications SEGFAULT when the domain is not started.</b><br/>
            <i>
              In the case no DDS domain is running but there is still a dirty
              shared memory segement present from an old instance of Spliced.
              It can happen that when an application is started, the application
              can crash with a SEGFAULT.
              <br><br>
              <b>Solution: The defect is fixed and the application will no
              longer crash because of this.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3455
          </td>
          <td>
            <b>The durability service should improve the memory used during alignment.</b><br/>
            <i>
             The durability service temporarily caches received alignment data
             until the set for a specific partition-topic combination is
             complete. The algorithm implemented there could be improved to
             reduce the amount of memory used during this phase.
              <br><br>
              <b>Solution: The durability service now stores unregistrations is
              a much more memory-efficient way reducing the memory overhead for
              alignment to a minimum.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3457/10241<br>
            dds3458/10242<br>
          </td>
          <td>
            <b>Crash of networking and/or durability during due to memory exhaustion.</b><br/>
            <i>
              The networking and durability services could crash when the shared
              memory was exhausted.
              <br><br>
              <b>Solution: The services now check the available
              memory threshold and does not claim more memory when the threshold
              has been reached. Furthermore they will terminate when no more
              memory becomes available within a few seconds.</b>
            </i>
          </td>
        </tr>
       </table>
      </table>
    </p>
    <p><h3>5.7.4p5</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3248/<br>9908
          </td>
          <td>
            <b>Partition expressions not matched properly.</b><br/>
            <i>
              In case an application publishes/subscribes to multiple partitions
              and the list of partitions has names that are sub-strings of one
              of the others in the list, some partitions may be ignored. Even
              though communication within a node and communication over the
              network using the native networking service still works correctly,
              this issue causes communication over the network to fail when
              using the ddsi networking service and it also causes listeners
              not to be triggered on matched subscriptions and publications.
              <br><br>
              <b>Solution: The error in the pattern matching algorithm in the
              kernel has been repaired.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3251/<br>9912
          </td>
          <td>
            <b>Alignment of non-volatile data temporary requires an additional shared memory size of all unregistration messages that will be aligned.</b><br/>
            <i>
              During the alignment of a set of data, the durability service
              temporarily allocated a complete sample for each unregistration
              message that needs to be aligned in order to keep track of the
              instance. In cases where a lot of instances exists and samples
              are large, this had a large impact on the amount of shared memory
              that needed to be available.
              <br><br>
              <b>Solution: The durability service now allocates one message for
              an unregistration at the time and frees it before allocating the
              next one. This ensures only the size of one extra sample needs to
              be available in shared memory, independent of the number of
              unregistration messages to align.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3431/<br>10188
          </td>
          <td>
            <b>ospl -f always waits worst-case terminate period.</b><br/>
            <i>
              When 'ospl -f' receives a TERM signal, it will stop spliced and
              wait a configured amount of time (4s + Lease/ExpiryTime +
              ServiceTerminatePeriod) for that to finish. If spliced doesn't
              normally finish during that period, ospl will forcedly stop the
              processes and cleanup the resources. The issue is caused by a
              deadlock in the 'ospl -f'. When ospl decides to shut-down the
              spliced due to the reception of a signal, the (single-threaded)
              tool is waiting for the 'system' call to return (reading the
              exit-status from the process) while in the meantime checking the
              existence of the process by means of 'kill(pid, 0) != -1'. That
              check does however not yield the desirec outcome since kill will
              only return -1 if pid does not exist (and note that an existing
              process might be a zombie, a process which already committed
              termination, but has not yet been wait()ed for).
              <br><br>
              <b>Solution: The solution is to call waitpid in the
              signalhandler of ospl, before kill(pid,0) is used to check if the
              spliced process is gone. Additionally, the signalhandler sets the
              exitstatus returned by waitpid, because this status is no longer
              correctly returned by the system function(the process has already
              been wait()ed for).</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.7.4p4</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3240<br>
          </td>
          <td>
            <b>RTNetworking did not correctly check eventmask for NEW_GROUP events</b><br/>
            <i>
              Instead of checking if the V_EVENT_NEW_GROUP was set in the eventmask of an observer,
              networking checked if the mask was equal to V_EVENT_NEW_GROUP, and this test failed when
              multiple events had occurred before networking (or any other service) had the chance to react.
              <br><br>
              <b>Solution: The check is modified, so networking only checks for the related event-bit.</b>
            </i>
          </td>
        </tr>
      </table>

    <p><h3>5.7.4p3</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3393/<br>10133
          </td>
          <td>
            <b>StoreSessionTime not respected in all cases</b><br/>
            <i>
              The StoreSessionTime configuration item was ignored for SMP stores,
              which could cause data to be synchronised very often. Some
              use-cases require less synchronisations to be performed in order
              to improve throughput.
              <br><br>
              <b>Solution: In order to allow for delayed flushing, the StoreSessionTime
              configuration is now also respected by the MMF persistence
              implementation.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.7.4p2</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3155/<br>9755
          </td>
          <td>
            <b>Delayed initial durability alignment</b><br/>
            <i>
              Previously, when a system had a late-joining node with persistent data,
              this persistent data was not injected. This behavior was considered valid,
              since it can be disruptive to inject historical data in a running system.
              However, in a system where no data has been written, it can be desirable
              to do a delayed injection of persistent data from a late-joining node.
              <br><br>
              <b>Solution: A new option has been implemented where, in the case where no
              writer has been created in any of the partitions in a durability namespace,
              persistent data from a late-joining node can still be aligned.
              This functionality has to be explicitly configured on a namespace policy,
              using the delayedAlignment option. See the configurator tool (osplconf)
              for more details.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3302
          </td>
          <td>
            <b>New tool mmfd available</b><br/>
            <i>
              A new tool has been added called 'mmfd' that can be used to dump the
              contents of an 'MMF' type persistent file. You must pass the tool the
              name of the persistent file and its mapping address, and then it allows
              you to browse through the contents of the mmf file and to monitor its
              memory statistics.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3409
          </td>
          <td>
            <b>mmstat tool extended</b><br/>
            <i>
              mmstat has been extended with an option to order its object references
              (in case of the 't' or '-T' mode) by objectCount/objectSize/TotalSize.
              This helps you to focus on those object types that have the most impact
              on the consumption of shared memory, by listing the biggest
              objectCount/objectSize/TotalSize on the top. You can also limit the
              the amount of items being displayed to only the top 'n' items, where
              'n' is a command-line parameter. For this purpose 2 new command-line
              parameters have been added:<br>
              -o &ltC/S/T&gt : displays an ordered list sorted by objectCount/objectSize/TotalSize.<br>
              -n &ltn&gt : displays only the top 'n' items in this list.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3410
          </td>
          <td>
            <b>Performance and memory enhancement for data models with empty strings</b><br/>
            <i>
              Currently the OpenSplice database allocates separate empty strings
              as separate chunks of memory, each having their own '\0' terminator
              and headers. In applicationss with huge amounts of empty strings,
              a lot of memory could be saved if the database allocates 1 empty
              string by default, and then always points to the location of this
              default string (increasing its reference count accordingly) when an
              empty string needs to be expressed.
              <br><br>
              <b>Solution: Empty strings in the database now always refer to the
              same chunk of memory (containing the '\0' terminator), instead of
              allocating each empty string separately. In case of data models that
              use huge numbers of empty strings, this can save a lot of
              performance and memory.</b>
            </i>
          </td>
        </tr>
      </table>
    <p><h3>5.7.4p1</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3376/</br>10114
          </td>
          <td>
            <b>A dispose_all_data() applied consecutively on several topics does
            not remove all data</b><br/>
            <i>
              A regular DataWriter and DataReader are used to transport the
              dispose_all_data command. However, both DataWriter and DataReader
              have their HistoryQosPolicy set to KEEP_LAST with a depth of 1.
              Since each splice deamon has its own private instance, consecutive
              dispose_all_data commands that originate from a single source will
              overwrite previous commands in its DataWriter (in case a resend
              is required) or in one of more splice daemon DataReaders (in case
              they haven't processed the command before the next command
              arrives). This may lead to missed dispose_all_data commands
              resulting in not disposing the data nor notifying the applications.
              <br><br>
              <b>Solution: Both internal DataWriter and DataReader now use a
              KEEP_ALL history policy to ensure all commands are sent and
              received.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3385
          </td>
          <td>
            <b>Durability tracing level NONE missing in configurator</b><br/>
            <i>
              The configurator tool did not allow configuring a value of NONE
              for the durability service tracing verbosity that is supported by
              the service.
              <br><br>
              <b>Solution: The NONE verbosity level has been added to the
              configurator tool.</b>
            </i>
          </td>
        </tr>
      </table>
    <p><h3>5.7.4</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3200/</br>9845
          </td>
          <td>
            <b>The 'ospl list' command does not list all running domains</b><br/>
            <i>
              In case an OSPL_URI environment variable was set, the 'ospl list' command
              only showed the domain associated with that URI (in case that was running).
              <br><br>
              <b>Solution: The 'ospl list' command no longer takes the OSPL_URI environment
              variable into account and simply lists all running domains.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3211/</br>9859
          </td>
          <td>
            <b>Networking crash when receiving a TERM signal</b><br/>
            <i>
              Terminating the real time networking service by sending it a TERM signal
              is not supported, but doing it sometimes resulted in a segmentation-fault.
              <br><br>
              <b>Solution: The termination request is now fully ignored and the networking service no longer crashes.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3274
          </td>
          <td>
            <b>Umask was not correctly applied on SHM and keyfile</b><br/>
            <i>
              The umask was interpreted wrongly, potentially causing unexpected permissions on
              the shared-memory segment and keyfile.
              <br><br>
              <b>Solution: The umask is interpreted as expected now. In case only read or write
              permission are specified for an access category, that category will be granted both read and write permissions on the domain.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3315/</br>10030
          </td>
          <td>
            <b>Durability service fails to inject persistent topic definitions in case of dependency conflicts</b><br/>
            <i>
              In some scenarios the mmf store failed to inject its persistent topic definitions when started from a
              clean Domain. In the error log it would write messages stating that the Deserialize failed, and later on
              that it failed to register the topic type.This issue was caused by the fact that the persistent store
              recorded the wrong entry-point for its persistent datatypes: instead of pointing directly to the structured
              datatype definition it was pointing to the outer-most module of this datatype. In case other datatypes
              were specified in the same module, the deserializer would try to deserialize all datatypes from that module
              at the same time.
              <br><br>
              <b>Solution: Those issues have now been fixed by making sure that the a clone on a type definition
              always returns the same entry point as the original, which in this case is the structured datatype
              itself. This way the mmf store should be able to inject its persistent topic definitions without
              any further problems, even if their datatypes are defined in the same module.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3316/</br>10031
          </td>
          <td>
            <b>Persistent store sometimes contains duplicate instances</b><br/>
            <i>
              Instances that have a string as their key (either an IDL string or an IDL char array that was transformed
              by a #pragma cats) were duplicated in the mmf type persistency store when updates are
              applied to them.
              <br><br>
              <b>Solution: A fix has been applied to mmf store to avoid duplication.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.7.3</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3156/</br>9753
          </td>
          <td>
            <b>Reliablility problem in networking when running multiple nodes.</b><br/>
            <i>
              When running real time networking and nodes are communicating over a reliable channel,
              it is possible that when a node is shutdown other nodes in the network
              start to lose communication with each other due to a corruption in the
              network administration.
              <br><br>
              <b>Solution: The defect in the network administation algorithm is now fixed.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3290</br>
          </td>
          <td>
            <b>Native networking retransmits to the wrong IP address</b><br/>
            <i>
              Native networking should retransmit to the IP address of the destination
              machine, but uses the global partition's destination address instead.
              The result is that all machines receive the retransmissions. When combined
              with network partitions, machines that never received the original data
              may get the retransmissions destined for another node, and the network floods.
              <br><br>
              <b>Solution: The defect in native networking is now fixed.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.7.2p1</h3></p>
     <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3236</br>
          </td>
          <td>
            <b>Durability MMF store destroys database on exit and snapshot</b><br/>
            <i>
              The database of an MMF store was destroyed in case durability
              detached the store from memory, effectively corrupting the data. This
              behavior is related to the introduction of the new memory manager, which
              performs processing that has to be explicitly stopped before database detachment.
              Stopping this processing implied destroying the database, which caused the
              described issue.
              <br><br>
              <b>Solution: A suspend\resume mechanism for the memory manager now allows
               durability to explicitly start\stop memory manager processing without
               destroying the database."
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.7.2</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            9127/<br>dds2821</br>
          </td>
          <td>
            <b>OpenSplice DDS should not start if ReportPlugin configuration is invalid or fails to initialize</b><br/>
            <i>
              If a ReportPlugin configuration is specified and that ReportPlugin contains invalid data or fails
              to intialize OpenSplice DDS still starts.  If the ReportPlugin contains invalid data or fails to
              initialize OpenSplice DDS should fail to start.

              <br><br>
              <b>Solution: The solution was to report any invalid data found in a ReportPlugin
                 or any failure to initialize a ReportPlugin to the default error log and for
                 OpenSplice DDS to fail to start in these circumstances.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.7.1</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            9682/<br>dds3137</br>
          </td>
          <td>
            <b>networking service crash with synchronous write acknowledgments</b><br/>
            <i>
              The native networking service may crash during synchronous write operations.
              This was because the management of a table of WaitList objects was found
              not to be thread safe.
              <br><br>
              <b>Solution: The solution was to add appropriate mutex locking
              within the synchronous write administration in order to make
              the mechanism thread safe.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9298/<br>dds2913</br>
          </td>
          <td>
            <b>Intermittent crashing of OpenSplice Tuner</b><br/>
            <i>
              The tuner crashed when an invalid entity was passed
              from the control and monitoring API, while trying to
              report that the entity could not be claimed.
              <br><br>
              <b>Solution: A check is added to the function reporting the error so it doesn't crash on an invalid entity.
              An error-report is added to the control and monitoring API which reports the xml-string when it contains
              an invalid entity.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2998
          </td>
          <td>
            <b>OpenSplice can fail to start as a Windows service but report that is has started successfully.</b><br/>
            <i>
              If the OpenSplice daemon failed to start under certain circumstances when installed to run as a windows service,
              the service control manager would not detect this and would report that the service was running.
              The circumstances included if the machine had not been rebooted after installation and if the system
              path or other environment variable values were incorrectly set.
              <br><br>
              <b>Solution: If the OpenSplice daemon fails to start when installed as a windows service in these circumstances
              this is detected and an error message is logged to the Windows EventLog. The windows service will exit and indicate
              an error to the Service Control Manager. This allows the user to configure recovery actions for failure of spliced.
              See http://technet.microsoft.com/en-us/library/cc738230%28WS.10%29.aspx for details of this.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3078
          </td>
          <td>
            <b>OpenSplice emits spurious error message regarding a failure accessing temporary directories on Windows.</b><br/>
            <i>
              OpenSplice emitted spurious error messages regarding a failure accessing temporary directories on Windows.
              The messages were typically of the form "Description : Unable to create directory 'C:' within path ... Errorcode: 5"
              <br><br>
              <b>Solution: OpenSplice no longer emits spurious error message regarding a failure accessing temporary directories on Windows.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            3089
          </td>
          <td>
            <b>Networking service crashed on startup when no network interfaces found.</b><br/>
            <i>
              If the OpenSplice native networking service was started before any network
              interfaces were available from the operating system, it would lead to undefined
              behaviour.  This has been corrected and the behaviour now is that the networking
              service will write a message to the ospl-error.log indicating that no interfaces
              could be found and networking will then terminate.
              <br><br>
              <b>Solution: The networking service will now exit gracefully and not crash if
                it cannot find any network interfaces it can bind to. It is a requirement
                that OpenSplice can only be started once the operating system is fully active
                and a network interface is available to allow the networking service to run.
               </b>
            </i>
          </td>
        </tr>
      </table>
    </p>

    <h2><a name="issues_not_api">Fixed Bugs and Changes not affecting API</a></h2>
    <p><h3>5.7.0</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7255/dds2239<br/>
            7653/dds2405
          </td>
          <td>
            <b>Memory thresholds not always obeyed by services</b><br/>
            <i>
              When memory thresholds were defined, some services would not check
              the threshold status before allocating shared resources.
              <br><br>
              <b>Solution: The routines of services that allocate shared memory
              now obey the rules regarding memory-thresholds.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8957/dds2697<br/>
          </td>
          <td>
            <b>Unexpected signal handling on SIGABORT or SIGSEGV</b><br/>
            <i>
              The implemented signal handling for POSIX platforms makes it
              impossible to generate application core files because the
              clean-up in ospl relies on exit() being called.
              <br><br>
              <b>Solution: A new signal handling mechanism has been
              implemented for POSIX-compliant platforms. The reference
              manuals have not been updated properly to reflect the changes,
              which is marked in the
              <a href="./dcps_known_issues.html">DCPS Known Issues</a> section as
              dds3080 that also describes the new behaviour.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9377/dds2993
          </td>
          <td>
            <b>Problem using dds in namespace</b><br/>
            <i>
              The code that is generated by the OpenSplice IDL pre-processor for
              C++ does not use the correct scope for the DDS module
              (DDS::&lt;X&gt; instead of ::DDS::&lt;X&gt;). In case a DDS sub-module is used
              for application-specific types, the types are incorrectly resolved.
              <br><br>
              <b>Solution: The IDL pre-processor has been adapted to generate
              the absolute scope for internal DDS types.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9388/dds3027
          </td>
          <td>
            <b>Incorrect dereferencing in idlpp-generated code for bounded strings</b><br/>
            <i>
              The copyIn routine for (array of) bounded strings, generated by idlpp, contained
              a bug related to incorrect dereferencing. The code in question is only used if
              it is compiled with the OSPL_BOUNDS_CHECK flag.
              <br><br>
              <b>Solution: Corrected the idlpp code generation.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9470/dds3039
          </td>
          <td>
            <b>64bit support for MMF store</b><br/>
            <i>
              The 4GB limitation on MMF store size is removed. On 64bit platforms it will now be possible to specify sizes above 4GB.
              <br><br>
              <b>Solution: Adjusted the configuration and operating system abstraction to allow for passing of 64-bit values.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9476/dds3047
          </td>
          <td>
            <b>Wireshark plugin is out of date and does not compile</b><br/>
            <i>
              The plug-in referenced old documentation that made it difficult to compile manually. Also, the latest networking
              protocol changes were not applied.
              <br><br>
              <b>Solution: Updated the documentation and protocol decoding for OpenSplice Networking.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3049
          </td>
          <td>
            <b>C# API is crashing when reading samples from the DCPSPublication and DCPSSubscription topics</b><br/>
            <i>
              Caused by incorrect idlpp output where the gapi representation of the struct containing the builtin topics
              is not referring to the gapi representations of its embedded QosPolicies, but to the C# representation of
              these QosPolicies. In most cases these representations have the same footprint, but in some cases
              (PresentationQosPolicy) it does not. That may cause wrong pointer evaluations in the CopyOut function.
              <br><br>
              <b>Solution: idlpp output corrected.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9459/dds3060
          </td>
          <td>
            <b>The 'c_bind' and 'c_select' symbols conflict between Eiffel and OpenSplice</b><br/>
            <i>
              One of the ospl libraries exports the 'c_bind' and 'c_select' symbols. These symbols conflict with symbols used in Eiffel
              <br><br>
              <b>Solution: The 'c_bind' and 'c_select' symbols have been renamed to respectively 'ospl_c_bind' and 'ospl_c_select'</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3072
          </td>
          <td>
            <b>Networking crash when using "reconnection_allowed" in multinode</b><br/>
            <i>
              In some circumstances the networking service can crash when the
              "reconnection_allowed" option is used due to the fact that the
              administration for a disconnected remote node is not cleaned up
              properly.
              <br><br>
              <b>Solution: The administration of the remote node is properly cleaned up.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>

    <p><h3>5.6.0p1</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3006</br>
          </td>
          <td>
            <b>Errors are logged for destruction of mutexes during shutdown on AIX</b><br/>
            <i>
              Errors were logged because of destruction of unused mutexes structs which had not been initialised.
              <br><br>
              <b>Solution: Cleanup of mutex destruction/removal of unused mutex.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds3021</br>
          </td>
          <td>
            <b>mmstat cannot be piped to a log file.</b><br/>
            <i>
              The mmstat tool exits immediately when stdin is not a tty.
              <br><br>
              <b>Solution: Updated mmstat to continue if stdout or stdin is not a tty.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>

    <p><h3>5.6.0</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2723 /</br>
          </td>
          <td>
            <b>Creation of DataReader with a Topic resulting from a find_topic call</b><br/>
            <i>
              Within OpenSpliceDDS a problem existed surrounding the creating of a DataReader
              with a Topic that was the result of a 'find_topic' call. The typeSupport that
              is needed by a DataReader must be registered for the same type name as used
              to create the DataReader's Topic. A Topic resolved by 'find_topic' call is
              implicitly created by using the default type name (the IDL type name).
              So if the DomainParticipant has registered the TypeSupport using an alias name
              that is different than the default name then OpenSpliceDDS will not be able
              to find the TypeSupport by its default name.
              <br><br>
              <b>Solution: The solution is that whenever a TypeSupport is registered it is
              now also always registered by its default name.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2787-1 /</br>
            9112
          </td>
          <td>
            <b>Exit-hook in JVM could be executed during a callback causing a deadlock
               on shutdown of a Java application</b><br/>
            <i>
              The exit-hook ensuring proper clean-up of entities created in Java could
              be called and executed during a listener-callback. This would cause a deadlock.
              The tutorial-code (e.g. the MessageBoard) could trigger this issue, but it
              could also occur when the application was terminated by issuing CTRL-C.
              <br><br>
              <b>Solution: The exit-hook has been wrapped in a separate thread, ensuring
              parallel execution of the clean-up code preventing the deadlock.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2787-2 /</br>
            9112
          </td>
          <td>
            <b>Freeing of process-space (user-layer) entities could cause spurious logs,
               hangs or crashes</b><br/>
            <i>
              During clean-up of entities in process-space (user-layer), invalid memory may be accessed.
              This could result in logs  about for example os_mutexUnlock-fails, but could also result in a crash or hang
              of the application, preventing proper shutdown.
              <br><br>
              <b>Solution: The offending code has been fixed to properly adhere
              to the locking and freeing sequence of user-layer entities.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2810 /</br>
            9112
          </td>
          <td>
            <b>DDS_RETCODE_TIMEOUT return-code of writes ambiguous when resource-limits
             are set on a synchronous writer</b><br/>
            <i>
              When resource-limits were set on a synchronous writer and DDS_RETCODE_TIMEOUT
              was returned, it was impossible to detect whether the timeout occurred due to
              the resource-limits or due to synchronisation with subscribed synchronous readers.
              <br><br>
              <b>Solution: On a synchronous writer a call which in the normal case would block
              on resource-limits now immediately returns DDS_RETCODE_OUT_OF_RESOURCES. A
              synchronous writer now only blocks (for maximally the time specified in the
              reliability.max_blocking_time) when data is not yet delivered to all subscribed
              synchronous readers.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2883 /</br>
            9009
          </td>
          <td>
            <b>On Windows, OpenSplice failed to run as a windows service if a 'Log on as'
            value of a non-elevated privilege user account is specified.</b><br/>
            <i>
              Global named objects could only be accessed from sessions that were
              interactively logged-in, or using accounts that corresponded to SID
              type Local System or Domain Administrator.
              <br><br>
              <b>Solution: The access control list has been relaxed & OpenSplice runs
              as a windows service if a 'Log on as' value of a non-elevated
              privilege user account is specified</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2968 /</br>
            9343
          </td>
          <td>
            <b>Variable assignment in release.com is not Korn shell compatible</b><br/>
            <i>
              Checking an environment variable within the release.com where it has not
              been set fails when using ksh.
              <br><br>
              <b>Solution: Change variable usage in release.com to ${VAR:=} which guarantees
               nothing is returned if the variable has not been set.</b>
            </i>
          </td>
        </tr>
       <tr>
          <td>
            dds2975
          </td>
          <td>
            <b>Reading/Taking invalid samples</b><br/>
            <i>
               Reading or Taking invalid samples could in certain scenario's result in a crash,
               or in samples that seemed to have a corrupted state
              <br><br>
              <b>Solution: Invalid samples will always be guaranteed to have legitimate key-values. The non-keyfields of an invalid
              sample (for which the valid_data field in the corresponding SampleInfo is marked FALSE) are NULLIFIED and should not
              be interpreted by an application, since this is the only situation in which null pointer strings can be encountered. </b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2980-1
          </td>
          <td>
            <b>Default ExpiryTime and ExpiryTime@update_factor for Lease element of the Splicedaemon modified</b><br/>
            <i>
              The defaults for the Lease element of the Splicedaemon configuration were incorrect.
              <br><br>
              <b>Solution: The defaults have been modified. The default ExpiryTime is now 10s,
              the default ExpiryTime@update_factor is 0.2, resulting in heartbeats being sent
              out every 2s. For more information or modifying the configuration files the
              configurator tool or deployment manual should be consulted.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2980-2
          </td>
          <td>
            <b>The default value for the standards conformance attribute of DDSI2 has been changed</b><br/>
            <i>
              The default for DDSI2 for its standards conformance was 'strict', which would cause high CPU
              and network-load when communicating with RTI, because RTI doesn't adhere to the specification.
              <br><br>
              <b>Solution: The default of DDSI2's standards conformance has been relaxed. The new default is
              'lax', providing the smoothest possible interoperability by default with vendors not adhering
              to the specification.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2988
          </td>
          <td>
            <b>Deadlock involving the waitset and status conditions</b><br/>
            <i>
              When a waitset is triggered by a statuscondition, then it will first lock the status condition,
              then the entity within the status condition. However if the entity is also deleted at the same
              time the locking strategy is reversed. The entity is locked first and then the condition is locked.
              This creates a deadlock scenario.
              <br><br>
              <b>Solution: The deadlock scenario has been removed by no longer locking the entity once the
              condition is locked. This is safe as the entity remains in consistent as long as the condition
              is not deleted and the condition can not be deleted without claiming the lock of the condition.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2991
          </td>
          <td>
            <b>Define log output directory on installation when OpenSplcie is installed as a windows service</b><br/>
            <i>
              When OpenSplice is installed as a windows service, the environment is configured such that OpenSplice will
              write log files into a directory within the current users profile. On some Windows installations the default
              service user account LocalSystem does not have a profile directory and logs cannot be created.
              <br><br>
              <b>Solution: The OpenSplice installer prompts for the user to supply a system wide directory path for all
              OpenSplice logs when OpenSplice is installed as a windows service.</b>
          </td>
        </tr>
      </table>
    <p><h3>5.5.1p2</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2984</br>
          </td>
          <td>
            <b>Building examples on AIX fails</b><br/>
            <i>
          The -qobjmodel=ibm flag had been removed from the build but not example makefiles
              <br><br>
              <b>Solution: The -qobjmodel=ibm has been removed from the example makefiles</b>
            </i><br>
            <b>Java based tools require Sun JVM which is not available on AIX</b><br/>
            <i>
          The osplconf and ospltun tools will not start without a Sun JVM.
              <br><br>
              <b>Solution: The JVM vendor check has been removed</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.5.1p1</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2940 /</br>
            9322
          </td>
          <td>
            <b>Connection problem on solaris 10</b><br/>
            <i>
              With the implementation of IPv6 support a bug was introduced that
              caused connection problems on Solaris 10 platforms, when using
              the networking service. This resulted in inability to communicate
              with other nodes and the following ERROR was reported:
              "Description : sendto returned errno 22 (Invalid argument)".
              The root-cause was a wrong sockaddr size that was supplied to
              the sendto() call.
              <br><br>
              <b>Solution: The issue is now fixed by supplying the correct size,
              based on the used addressing-method ( IPv4 or IPv6 ).</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.5.1</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2267 /</br>
            7285
          </td>
          <td>
            <b>ospl stop does not clean properly</b><br/>
            <i>
              On 'ospl stop', OpenSplice services do not terminate when the
              splice-daemon has already terminated, causing the key file as
              well as the services to remain active until all services have
              detected the termination of the splice-daemon. This detection
              time is determined by the //OpenSplice/Domain/Lease/ExpiryTime
              setting.
              <br><br>
              <b>Solution: On start-up the splice-daemon now runs in its own
              process group and this group includes all services it starts.
              On ospl stop, this group is killed in case the splice-daemon has
              already terminated and the other services have not detected it
              yet.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2449 /</br>
            7946
          </td>
          <td>
            <b>Durability and networking still running after spliced death</b><br/>
            <i>
              Other services keep running If the splice-deamon is killed.
              <br><br>
              <b>Solution: All services are now actively monitoring whether
              the splice-daemon updates its lease and terminate when they
              detect this is no longer happening. This detection
              time is determined by the //OpenSplice/Domain/Lease/ExpiryTime
              setting. To ensure immediate termination of the services, an
              'ospl stop' can be issued by the user. This will actively
              kill the remaining services and clean up the shared memory.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2497 / dds2868</br>
            9169
          </td>
          <td>
            <b>Primitive type array may get corrupted when fragmented on the network. </b><br/>
            <i>
              When a data sample containing an array of primitive types is
              transported by the networking service between nodes, corruption of
              the content can occur when the sample is fragmented over multiple
              network packets by the networking service.
              <br><br>
              <b>Solution: The bug in the defragmentation/deserialisation
              algorithm that caused this behaviour has been fixed.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2732</br>
          </td>
          <td>
            <b>On Windows, OpenSplice shuts down when any interactive user session logs off.</b><br/>
            <i>
              OpenSplice is shutting down when it received the Windows control
              event CTRL_LOGOFF_EVENT.
              <br><br>
              <b>Solution: OpenSplice now ignores the Windows control event
              CTRL_LOGOFF_EVENT and does not shutdown.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2761/</br>
            9058
          </td>
          <td>
            <b>Copy of idl-union sets the m__d_set flag making it different from the original</b><br/>
            <i>
              The idlpp tool generates incorrect code for making a copy of an
              idl-union, which results in a copy that is different
              from the original.
              <br><br>
              <b>Solution: The idlpp tool has been modified to generate the
              correct code for copying unions.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2818 /</br>
            9123
          </td>
          <td>
            <b>DataReader no more notified after a dispose_all_data</b><br/>
            <i>
              Disposes of empty instances end up invisible to the application
              due to the fact the DataReader instance administration is not
              updated properly for empty instances. Furthermore, the Tuner
              tool is not able to cope with dispose messages that were
              triggered by dispose_all calls due to a missing check in the
              Tuner code.
              <br><br>
              <b>Solution: The DataReader administration is updated properly
              for empty instances as well and the Tuner now is able to handle
              all types of dispose messages.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2823</br>
          </td>
          <td>
            <b>write_w_timestamp uses wrong base time for computing blocking duration</b><br/>
            <i>
              write_w_timestamp determines when to return with a timeout by
              adding max_blocking_time to the time-stamp supplied by the
              application, instead of adding it to the current time. The
              application-supplied time stamp may be long in the past, causing
              spurious timeouts.
              <br><br>
              <b>Solution: The blocking time is now based on the current time
              instead of the supplied time.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2841</br>
          </td>
          <td>
            <b>DDSI configuration for compatibility mode can't be set.</b><br/>
            <i>
              The configurator tool does not allow configuring the already
              supported compatibility mode for ddsi. This mode determines how
              strict ddsi spec compliance is enforced to allow communication
              with other less-compliant ddsi implementations.
              <br><br>
              <b>Solution: The configuration parameter has been added to the
              configurator.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2911</br>
          </td>
          <td>
            <b>Tuner crashes when creating a shared reader</b><br/>
            <i>
              Creation of a shared DataReader is only possible in case the
              Subscriber is also a shared Subscriber. The Tuner never creates
              shared Subscribers in case a shared DataReader needs to be
              created. Creation of a shared DataReader for a non-shared
              Subscriber results in a crash.
              <br><br>
              <b>Solution: The Tuner now explicitly checks whether a shared
              DataReader is to be created. If so, if will make sure to create a
              shared Subscriber for it and if the user tries to create a shared
              DataReader for a non-shared Subscriber, it will report an error
              and refuse to create the DataReader.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2923 /</br>
            9314
          </td>
          <td>
            <b>The same sample is received several times with DDSI2</b><br/>
            <i>
              With DDSI2 time stamps may be off by 1ns and a single sample may
              be received twice with different time stamps DDSI2 performs
              conversion between DDS time stamps (seconds + nanoseconds) and
              DDSI time stamps (64-bit fixed-point with the binary point to the
              left of bit 31, i.e., seconds + the fraction of a second as a 32
              bit unsigned integer). The conversion routines contained a
              rounding error that caused the result of a round-trip through
              the conversion routines to be 1ns before the original.
              Because of this a data reader on the same node as the data writer
              would often observe a different source time stamp than a data
              reader on a remote node connected via DDSI2 did. This is part one
              of the issue.

              Part two of the issue, receiving a sample multiple times with
              different source time stamps was caused by an interaction with the
              durability service alignment procedure. The durability services
              interact among themselves via a special encoding of the data,
              which does not suffer from this rounding error. Hence, If a
              durability service was receiving data from its peer on the node
              where the data was originally published, while the writer was also
              sending data directly, some samples would arrive twice, with
              different time stamps. Usually the latency in data forwarding
              through the durability service is longer than that of the normal
              data transmission path, and this, combined with the rounding
              causing the timestamp to be 1ns early, caused the copy received
              via the durability services to be accepted as a valid new sample.
              <br><br>
              <b>Solution: The conversion routines have been fixed. The DDSI
              standard does not define the conversion routines in sufficient
              detail to guarantee that all implementations will interpret time
              stamps the same way. Similar issues with time stamps may therefore
              appear in a system environment in which multiple vendors' DDS
              implementations are interoperating.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.5.0</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2224</br>
          </td>
          <td>
            <b>Usability and minor error corrections with the OpenSplice Tuner.</b><br/>
            <i>
              Minor usability enhancements and edge case minor errors were identified
              with the OpenSplice Tuner.
              <br><br>
              <b>Solution: Implemented small fixes to improve usability and address edge case errors.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8237 /</br>
            dds2470 /</br>
            CR_342
          </td>
          <td>
            <b>Daemon configuration scoped differs for different attributes</b><br/>
            <i>
             Locking the daemon in memory on Linux must be specified outside the scope
             of &LT Domain &GT to be effective while the attributes for setting the scheduling
             priorities of the threads on VxWorks must be specified within the &LT Domain &GT
             to be effective. This should be consistent for all attributes
              <br><br>
              <b>Solution: The daemon is now locked within the &LT Domain &GT to be consistent will all other
              attributes.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2491</br>
          </td>
          <td>
            <b>Ref counted object compilation errors with TAO</b><br/>
            <i>
              Ref counted objects on recent version of TAO will cause compilation errors<br><br>
              <b>Solution: Update ORB abstraction for DOC group TAO ccpp API. ::CORBA::LocalObject is refcounted
    from TAO 1.6.4/5 onwards</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2574</br>
          </td>
          <td>
            <b>Durability fails to align starting node under heavy load</b><br/>
            <i>
               When a system was experiencing heavy load, durability sometimes
               lost nodes because heartbeats were not received on time. Because of
               an optimization in the durability protocol, the status of groups
               partition topic combination) was not properly aligned when rediscovered.
               This caused problems with the alignment of other durability nodes,
               which never left the alignment state.<br><br>
              <b>Solution: After a node is rediscovered, durability sends requests
               for all groups that are not complete. This ensures that the durability
               node always has the last state.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2593</br>
          </td>
          <td>
            <b>Windows - CLASSPATH environment variable changed after compiling Java DLRL example</b><br/>
            <i>
              After compiling the Java DLRL Tutorial the CLASSPATH environment variable is changed from the default after
              running the release.bat script.
              <br><br>
              <b>Solution: Corrected the Java DLRL Tutorial batch file and also found this issue when running the ospltun.bat script so
              fixed that aswell.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2650</br>
          </td>
          <td>
            <b>Issues with using the domain name instead of URI on windows</b><br/>
            <i>
              Using the domain name, instead of URI, in a create_participant()
              call would fail on Windows if the proxy between application and OpenSplice
              kernel was not initialized yet. Also a non-default shared memory
              mapping address, supplied in the configuration file, was ignored.
              <br><br>
              <b>Solution: The proxy between application and OpenSplice daemon is now
              properly initialized in the case where the first create_participant call
              of an application passes the domain name instead of URI. The mapping
              address is now stored in the shared memory keyfile so it can be retrieved
              from the keyfile instead of config file URI.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2656
          </td>
          <td>
            <b>Added missing networking parameters to the configurator</b><br/>
            <i>
              The following parameters are not documented in the configurator but are in the deployment manual:
              <br>
                 - NetworkService/Discovery/Receiving/DeathDetectionCount<br>
                 - NetworkService/Discovery/Sending/Interval
              <br><br>
              <b>Solution: Added to configurator.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2661
          </td>
          <td>
            <b>Durability service tracing log corruption</b><br/>
            <i>
               Log messages used to be written to the tracing log in two steps: first
               the header containing a timestamp, state and source of the message,
               then the actual message. This caused incidental corruptions of the log
               file when headers and messages are written in incorrect order.
              <br><br>
              <b>Solution: Commit the complete message to the log file in a single action
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2693
          </td>
          <td>
            <b>Durability merge policy not applied if fellow node has not confirmed master</b><br/>
            <i>
               The merge policy mechanism would check if a potential merge fellow had confirmed its master.
               An unconfirmed master was a reason to not merge, since it was assumed that merging
               with an inconsistent node would unnecessarily cause a network load while the same data
               would be available from a different fellow that did meet all merge conditions, or the node
               would cause a new merge trigger as soon as it did confirm its master. There are however
               situations in systems with multiple nodes and roles, where data can only be retrieved by
               merging with a fellow even if that did not confirm its master yet.
              <br><br>
              <b>Solution: The 'confirmed master' is no longer a condition for a merge action.
              Instead the fellow state is checked. A merge action with a fellow that has an unconfirmed
              master is only carried out if that fellow is past the initial alignment state.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2696
          </td>
          <td>
            <b>Incorrect error reporting of durability error</b><br/>
            <i>
               Randomly, at system start up, durability logs errors "Topic not (yet) known".
              <br><br>
              <b>Solution: After investigation, there was no error and therefore no need for this error message to be
              reported. It has been removed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9035 /</br>
            dds2745
          </td>
          <td>
            <b>VC++ 2005 Compiler Error C2026 : line too big with idlpp</b><br/>
            <i>
               idlpp can generate code that is too big for the cl.exe compiler.
              <br><br>
              <b>Solution: Generated code is now blocked into approx 100 characters to
              avoid exceeding the microsoft limit. The blocks vary depending on where
              the split occurs (between 2 xml tags) to ensure its user friendly to read.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8986 /</br>
            dds2749
          </td>
          <td>
            <b>Fix for Memory leak in C and C++ TypeSupport constructor</b><br/>
            <i>
              In code generated by the IDL preprocessor various memory leaks were found,
              which caused strings to leak. In the generated code, strings were allocated
              and passed to the parent constructor of the TypeSupport constructor,
              but never freed. The other leak was in TypeSupport::register_type()
              where a string was allocated when parameter type_name was NULL, and never freed.
              <br><br>
              <b>Solution: In the generated code the strings are no longer allocated on heap,
              but are hard-coded and returned as 'const char *'. Another leak has been fixed
              where a string was not freed after a call on TypeSupport::register_type()
              with parameter type_name = NULL
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2753
          </td>
          <td>
            <b>Durability service gets stuck in infinite loop during master selection</b><br/>
            <i>
               After a short period of one-way traffic between two hosts running the durability
               service, one of the hosts may fail to process a namespaces request sent by
               the durability service of the other host. Since two-way communication is
               restored shortly after, the reliability protocol cannot detect this. Thus
               the other host waited indefinitely on a reply to the namespaces request.
              <br><br>
              <b>Solution: The master selection algorithm now keeps a record of all nodes
               that haven't replied to a namespaces request in a timely manner. If, after a
               short while, these nodes are still alive, they apparently missed the namespace
               request and a new request is sent. Precautions are taken so that this behaviour
               will not cause network spikes.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2786
          </td>
          <td>
            <b>Many Instance Handles causes performance degradation on Windows platforms</b><br/>
            <i>
               The integrity of each InstanceHandle is protected by a mutex that
               is shared by all DDS processes. On Windows platforms, the
               construction and destruction of these shared mutexes leads to a
               significant performance degradation when a large number of
               instances are created and/or deleted.
              <br><br>
              <b>Solution: The mutex has been removed from the instance handle
              and replaced with a mechanism that uses a counter in combination
              with atomic increment and decrement operations.
            </i>
          </td>
        </tr>
       </table>
    </p>

    <p><h3>5.4.2p3</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3108</br>
          </td>
          <td>
            <b>Problems starting spliced on VxWorks 5.5 with the mvme5100 target.</b><br/>
            <i>
               Problems starting spliced on VxWorks 5.5 with the mvme5100 target due to an issue with how our logging determined thread name.
              <br><br>
              <b>Solution: Fix for the logging systems routine to determind thread id, for cases where we have no stored thread id.</b>
            </i>
          </td>
        </tr>
        </tr>
       </table>
    </p>

    <p><h3>5.4.2p2</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds3084</br>
          </td>
          <td>
            <b>Problems loading libddscore.so on Vxworks5.5 ppc7448 due to relocation offset to large.</b><br/>
            <i>
               Problems loading libddscore.so on Vxworks5.5 ppc7448 due to relocation offset to large.
              <br><br>
              <b>Solution: We have added the -mlongcall compiler option.</b>
            </i>
          </td>
        </tr>
        </tr>
       </table>
    </p>

    <p><h3>5.4.2p1</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2747</br>
          </td>
          <td>
            <b>SIGSEGV signal coming from Java Garbage Collector crashes the app.</b><br/>
            <i>
             There are some bad interactions happening between Java's signal
             handling and signal handling set up by OpenSplice code. The JVM
             normally installs a signal handler for some signals, because
             there are situations where Java uses it internally for instance
             to allocate memory or wake-up a thread. OpenSplice blocks signals
             for a specific thread when accessing shared resources. Blocking
             of these signals prevents proper propagation to the JVM resulting
             in a crash.
              <br><br>
              <b>Solution: The blocking of signals is no longer necessary in
              OpenSplice due to a new approach for cleaning up shared resources
              with a dedicated thread and therefore threads are now no longer
              blocked. By pre-loading the jsig library that is delivered with
              each JVM, signal handlers of OpenSplice and the JVM are chained
              correctly and signals are handled by the correct signal handler.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2755</br>
          </td>
          <td>
            <b>Error in serializer w.r.t. module-less IDL-types.</b><br/>
            <i>
             When serializing a type without any module, the type-name
             turns out to be an empty string causing the full type-name to be
             "::::<type-name>" i.e. the non-present 'empty-string' module-name
             didn't prevent the superfluous "::" pair to be omitted.
              <br><br>
              <b>Solution: Types without a module are now serialized correctly
              by skipping the module without a name that is used internally
              for types without a module.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            9063 /</br>
            dds2762 /</br>
            SPCR1609
          </td>
          <td>
            <b>Finalise hook on the report plug-in not called during shutdown.</b><br/>
            <i>
             The finalise hook of the report plug-in is not called when
             detaching from a domain.
              <br><br>
              <b>Solution: The missing calls to the finalise hook have been
              added to the implementation.</b>
            </i>
          </td>
        </tr>
       </table>
    </p>
    <p><h3>5.4.2</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7738 / dds2440</br>
            8286 / dds2476<br/>
          </td>
          <td>
            <b>DDS keeps working after spliced daemon has stopped.</b><br/>
            <i>
             When the splice daemon is stopped while applications are still
             running, the applications continue to function and use DDS. This
             is considered unsafe, as the splice daemon can no longer manage
             various DDS related tasks. When the splice daemon is gone, the
             applications should no longer be allowed to use DDS.
              <br><br>
              <b>Solution: When the splice daemon stops the applications will
              now automatically detect this and be prevented from using DDS.
              The application will receive the ERROR return code when using
              DDS functions. The detection time of the applications is based
              on the configured lease expiry time, in the default configuration
              this means that applications will detect the splice daemon being
              gone within 60 seconds.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7886 / <br>dds2445
          </td>
          <td>
            <b>Durability alignment not robust.</b><br/>
            <i>
              When some of the first reliable packets that a node sends are lost on the network,
              the reliable communication between the nodes concerned may under some circumstances
              be blocked indefinitely in one or two directions for that channel. The visible
              result for the users is that the duribility services cannot allign, as they
              need reliable communication to work.

              <br><br>
              <b>Solution: The mechanism that handles joining of a new node in a reliable communication
              channel been extended, so that it can handle missing packets in any situation.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8826 /<br>dds2578
          </td>
          <td>
            <b>A QueryCondition that was not attached to a WaitSet failed to evaluate incoming samples.</b><br/>
            <i>
              A QueryCondition uses a cache to prevent multiple evaluations of the same sample.
              When a sample is inserted into a Reader that has a corresponding QueryCondition attached
              to a WaitSet, then the sample must be evaluated to determine whether or not to trigger the WaitSet.
              This evaluation result is then cached so that when a user reads/takes from the query, it does not need
              to re-evaluate the full reader content. A flag determines whether the cache is considered incomplete
              (i.e. the reader still contains samples that need to be evaluated) or whether the contents of the
              cache reflect all matching samples.<br><br>
              Due to an error in the query caching algorithm, the cache was only taking
              into account incoming samples when the query was attached to a WaitSet.
              This meant that the query cache could indicate that is was complete,
              while in fact the query still needed to evaluate some samples to substantiate that claim.

              <br><br>
              <b>Solution: The query cache is now marked incomplete by raising its
              flag when data is inserted while the query is not attached to a WaitSet.
              This causes the query to evaluate the reader content as well.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8813 /<br>dds2563
          </td>
          <td>
            <b>Method set_query_parameters on query conditions of dataviews did not function properly.</b><br/>
            <i>
              Parameters in a query were not correctly resolved, which lead to failing calls on
              set_query_parameters on query conditions of dataviews.

              <br><br>
              <b>Solution: Internal prefixing has been added so that parameters are correctly resolved.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2581
          </td>
          <td>
            <b>Java API lookup_topicdescription() function tries to find topic when lookup fails.</b><br/>
            <i>
              On the Java API : When lookup_topicdescription() is called and the lookup fails,
              OpenSplice tries to find the topic as if find_topic() was performed. This conflicts
              with the DDS spec. If the lookup fails, the call should return NULL.

              <br><br>
              <b>Solution: Using Java API, When lookup_topicdescription() is called and the lookup fails, NULL is returned.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2582
          </td>
          <td>
            <b>When calling find_topic, and the corresponding TypeSupport is not found, OpenSplice creates the TypeSupport.</b><br/>
            <i>
              When calling find_topic on a DomainParticipant, and the corresponding TypeSupport is not found,
              OpenSplice creates the TypeSupport. This conflicts with what is specified in the Tutorial and
              the Reference manual, and also can cause problems if the user then registers the same TypeSupport explicitly.

              <br><br>
              <b>Solution: When calling find_topic, no TypeSupport is created/registered as specified in the manual.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2595
          </td>
          <td>
            <b>Bounded Strings as character arrays</b><br/>
            <i>
              See <a href="#highlights">5.4.2 release highlights for more info</a>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2629
          </td>
          <td>
            <b>Improved performance for MMF persistence</b><br/>
            <i>
              See <a href="#highlights">5.4.2 release highlights for more info</a>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2633
          </td>
          <td>
            <b>Unable to configure scheduling properties of the main splice deamon thread.</b><br/>
            <i>
              There are no configuration options available to adjust the scheduling properties
              of the main splice deamon thread. This thread is responsible for the renewal
              of the liveliness lease of the splice deamon. By the inability to configure
              the scheduling properties there can be problems when the lease renewal time is set
              to a very small period. The splice deamon thread will then potentially not be able to renew
              the lease in time and thus will be considered dead to the services, whom will
              then terminate.
              <br><br>
              <b>Solution: The scheduling properties of the splice deamon thread can now be
              configured by setting the parameters in Domain/Watchdog/Scheduling.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2640
          </td>
          <td>
            <b>Deadline mechanism misbehaves when changing the deadline duration to a new value.</b><br/>
            <i>
              In OpenSpliceDDS 5.4.1 a bug was introduced in the deadline mechanism. This bug occurred
              in the scenario where an existing deadline duration for a datareader or datawriter was
              updated to a new, for example shorter, duration. The new (shorter) deadline duration did
              not come into effect immediately, but only after the previous (longer) deadline had expired
              or if a read or write occurred before the deadline expired. Afterwards the new, shorter,
              duration would be in effect as normal. The same issue occurred for longer durations being set,
              i.e., the deadline would expire based on the previous, shorter, duration.
              Due to this bug OpenSpliceDDS would not properly indicate the number of deadlines missed in
              specific scenarios. It could be too low or too high.
              <br><br>
              <b>Solution: The bug in OpenSpliceDDS has been resolved and new durations being set are now
              immediately taken into account when determining the deadline missed status.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2660
          </td>
          <td>
            <b>Java based floating license</b><br/>
            <i>
              Hostname limitations when using java based floating licenses
              <br><br>
              <b>Solution: Removed java based licensing and returned to C based licensing.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2661
          </td>
          <td>
            <b>Durability service tracing log corruption</b><br/>
            <i>
              Log messages used to be written to the tracing log in two steps: first the header
              containing a timestamp, state and source of the message, then the actual message.
              This caused incidental corruptions of the log file when headers and messages are
              written in incorrect order.
              <br><br>
              <b>Solution: Commit the complete message to the log file in a single action.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2666
          </td>
          <td>
            <b>size of LongDoublePair causing issues in idlpp</b><br/>
            <i>
              When idlpp source generated for one platform is compiled for a different target instead then it could cause memory corruption.
              <br><br>
              <b>Solution: The idlpp generated code now determines structure sizes at compile time instead of code generation time. Issue affected C & C++ language bindings.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2673
          </td>
          <td>
            <b>Cannot specify shared memory sizes of more than 4GB</b><br/>
            <i>
              The implementation of friendly names ticket in 5.4.1 (dds2241)
              has caused any shared memory database sizes over 4GB to be set to size
              required - 4GB, i.e. 5GB would be set to 1GB. The size specified in a config file
              was read in to a 32 bit integer (an unsigned long). Secondly, two additional size parameters
              (Domain->Listeners->StackSize and DurabilityService->Persistent->MemoryMappedFileStore->Size)
              of the config file were not user-friendly interpretable (e.g. 10M instead of 10485760 could not be used).
              <br><br>
              <b>Solution: The integer where the size is read into is now platform independent.
              This means that on 64bit platforms the size is read into a 64bit integer and on a
               32bit platform into a 32bit integer. Secondly the types of the two parameters have
               been converted from type 'long' to type 'size'.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2685
          </td>
          <td>
            <b>C&M module not included in the OpenSplice Community Edition</b><br/>
            <i>
              The C&M module was not included in the OpenSplice Community Edition.
              This meant that OpenSplice Community Edition users could not use the C&M module.
              <br><br>
              <b>Solution: The C&M module is included in the OpenSplice Community Edition.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2704
          </td>
          <td>
            <b>Splicedaemon heartbeat check no longer performed</b><br/>
            <i>
              The splicedaemon is responsible for checking whether heartbeats from
              remote splicedaemons are received to be able to detect a node disconnection.
              When this happens, it is responsible to clean up all resources from
              any entity from that node. This means that all instances that are
              currently registered by any DataWriter from the disconnected node
              need to be unregistered. As a result of that, instance states potentially
              change and the same goes for the ownership of (some of) the instances.
              This heartbeat checking mechanism has been implemented in the splicedaemon
              by means of registering a lease with the lease manager. Every time the lease
              expires, the service checks whether the connection with one or more nodes
              has been lost. Due to some re-design the lease to check for heartbeats has been
              replaced by a lease to send heartbeats. As a result, the splicedaemon now sends
              twice the amount of heartbeats it should and is no longer checking incoming
              heartbeats. As a result instance states can become incorrect, ownership is not
              taken over when it should and memory is not cleaned up properly.
              <br><br>
              <b>Solution: The faulty lease registration of heartbeat sending has
              been replaced by a heartbeat checking lease registration to make
              sure the mechanism works as before.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2705
          </td>
          <td>
            <b>The DDSI2 service (beta) may use incorrect type names for topics.</b><br/>
            <i>
             The DDSI2 service (beta) failed to include module names in the
             topic type names. Because of this, interoperability with other
             DDSI implementations was limited to topics of which the type was
             not declared in a module.
              <br><br>
              <b>Solution: The module names inside which the type is declared
              are now prefixed to produce a fully qualified type name.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2721
          </td>
          <td>
            <b>32-bit installers are generated for 64-bit platforms</b><br/>
            <i>
              Even though the product is properly compiled as 64-bit, the
              installer that is generated for 64-bit platforms turns out to
              be a 32-bit executable. This installer will therefore not run
              on 64-bit platforms that have no 32-bit libraries installed.
              <br><br>
              <b>Solution: The installer itself now is 64-bit when the product
              is generated for a 64-bit platform.
            </i>
          </td>
        </tr>
      </table>
    <p><h3>5.4.1p1</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2644 / dds2660
          </td>
          <td>
            <b>Java based floating license</b><br/>
            <i>
              Java license fixed to work with floating licenses.
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.4.1</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2241
          </td>
          <td>
            <b>User-friendly size-specification</b><br/>
            <i>
              The OpenSplice shared memory database size can now be specified in M (megabytes) or G (gigabytes) instead of just bytes.
              e.g. 256M, 2G.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7592/<br>
            dds2367
          </td>
          <td>
            <b>Report plug-in suppress ospl_error and ospl_info log output</b><br/>
            <i>
              When using a custom report plugin, it is not possible to suppress the output sent to
              ospl-error.log and ospl-info.log files.
              <br><br>
              <b>Solution: It is now possible to configure whether or not
              the output to ospl-error and ospl-info files need to be
              suppressed using the
              //OpenSplice/Domain/ReportPlugin/SuppressDefaultLogs tag.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2396 / bugzilla 37
          </td>
          <td>
            <b>write_dispose() returning RETCODE_PRECONDITION_NOT_MET</b><br/>
            <i>
              Invoking write_dispose() passing HANDLE_NIL as second parameter returns RETCODE_PRECONDITION_NOT_MET
              which conflicts with HANDLE_NIL (no handle) as stated in the manual.
              <br><br>
              <b>Solution: An additional check in an internal algorithm in the
              DataWriter has been added to ensure proper behaviour in this case.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7946<br>
            dds2449
          </td>
          <td>
            <b>OpenSplice services continue to run after the daemon process is terminated</b><br/>
            <i>
              Services do not detect when the splice deamon has crashed and keep running. When
              the splice deamon crashes abruptly the services would never terminate
              and had to be killed manually.
              <br><br>
              <b>Solution: Services will now properly detect when the splice deamon is no longer
              available in any situation. This is accomplished by means of a lease mechanism,
              where the splice deamon periodically renews a lease and services monitor this lease
              and react once they detect it has not been renewed and thus expired. When the expired
              lease of the splice deamon is detected it will result in the services shutting down in
              a normal manner. This does imply that services at worst wait the maximum duration of the
              lease, which by default has a duration of 60 seconds. If a quicker detection time is desired
              the duration of the lease should be configured to a shorter time value. This lease duration
              can be configured in the XML configuration at Domain/Lease using the OpenSplice DDS configurator tool.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8246/<br>
            dds2471
          </td>
          <td>
            <b>DBMS Connect: Mapping with float types</b><br/>
            <i>
              Whilst not entirely sure as to why MySQL reports the column to be of
              type FLOAT, when it has been specified as REAL (and the sql-mode of
              the connection/server contains REAL_AS_FLOAT).
              <br><br>
              <b>Solution: Extended DBMSConnect to be able to map both types on the internal float-type.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2513
          </td>
          <td>
            <b>TimeToLive not being set on multicast messages</b><br/>
            <i>
              Only the default operating system TTL value was being used for multicast, but the
              user defined value for unicast and broadcast was being respected.
              <br><br>
              <b>Solution: Now propogate correctly the TTL value for multicast messages, with the TTL applying
              at the network partition level.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2521
          </td>
          <td>
            <b>Error/success reporting on socket creation/binding incorrect in nw_socket_new()</b><br/>
            <i>
              The reporting of error/success in nw_socket_new(), was incorrect,
              which would lead to incorrect "success" message in the network tracing,
              also not all errors result in a proper error message in the error-log
              if creation or initialisation of a socket fails.
              <br><br>
              <b>Solution: Reporting corrected.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2524
          </td>
          <td>
            <b>java IDL generated files do not include the super.finalize() in finalize method</b><br/>
            <i>The output of idlpp did not include a call from finalize() to super.finalize() which
               is detected by static code analysis files.
              <br><br>
              <b>Solution: finalize() method now calls super.finalize().</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8650<br/>
            dds2526
          </td>
          <td>
            <b>Creation of query on dataReaderView fails</b><br/>
            <i>
              Creation of query on dataReaderView fails when the query
              addresses attributes within a record.
              <br><br>
              <b>Solution:</b>Prefixing of the internal name of attributes has
              been moved to the correct internal component.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2535
          </td>
          <td>
            <b>Robustness: Improve memory depletion detection so it accounts for free 'reusable' memory as well.</b><br/>
            <i>In the 5.4 release of OpenSplice DDS a new threshold value for the shared memory usage was introduced.
               When the available shared memory became less then the value of the threshold then OpenSplice DDS would prevent
               further allocations of data within shared memory. In the 5.4 version there was no recovery possible. Even if
               applications terminated and freed up memory and enough shared memory would be available, OpenSplice DDS would
               still not allow further allocations.  In effect once the threshold was reached it meant that the deamon had to be restarted.
              <br><br>
              <b>Solution: In this release the algorithm for detecting shared memory depletion has been improved to include freed memory in its calculations.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2540
          </td>
          <td>
            <b>Support for resource_limits.max_instances on DataWriter.</b><br/>
            <i>
              Functionality added to provide OMG specification compliance.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8813/<br>
            dds2563
          </td>
          <td>
            <b>DataReaderViewQuery created by MW08 sim is invalid, set_arg fail</b><br/>
            <i>An invalid DataReaderViewQuery is constructed from a valid
               expression provided by the application. After creation it is not
               possible to use it to read data or set its parameters due to
               a wrong translation from the application attributes to the
               internal representation of these attributes.
              <br><br>
              <b>Solution: The error in the mapping from application to
              internal attributes has been fixed.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2570
          </td>
          <td>
            <b>Report plugin to fail on invalid configuration</b><br/>
            <i>In v5.3 the report plugin was introduced, but on invalid configuration, would just
            continue and ignore the report plugin.
              <br><br>
              <b>Solution:The behaviour has been changed to fail when
            invalid report plugin configuration is used.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2598
          </td>
          <td>
            <b>Networking: MaxBurstSize is calculated using uncompressed sizes if compression is enabled</b><br/>
            <i>If compression is enabled for a networkchannel, the MaxBurstSize limitatiuon for that channel
               still uses the uncompressed size of the messages. This results in far less data being out on the
               wire than that is allowed by the "MaxBurstSize" setting. If compression is enabled, the MaxBurstSize
               limitation should be calculated over the compressed size.
              <br><br>
              <b>Solution: "MaxBurstSize" computations moved to lower level in code to take account of compression.</b>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2627
          </td>
          <td>
            <b>The Tuner always displays the synchronous_write ReliabilityQoSPolicy attribute as false</b><br/>
            <i>Due to an error in the parsing of the synchronous_write ReliabilityQosPolicy
               attribute, the Tuner displayed the attribute as being false in
               all cases.
              <br><br>
              <b>Solution: The parsing algorithm for synchronous_write in the Tuner has been fixed.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.4.0p1</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            8686/<br>
            dds2556
          </td>
          <td>
            <b>Durability service fails in an 8 node system</b><br/>
            <i>
              Due to a concurrency issue in the durability service, two threads
              could modify/read a specific variable at the same time. If that
              situation occurred it lead to a segmentation fault. The signal
              was caught and the service tried to clean up and terminate, but
              went into a spinning loop as a result of that, which was the
              second issue.
              <br><br>
              <b>Solution: </b>Access to the variable is now protected to make
              it thread-safe and also the service will no longer get
              into a spinning loop when an error occurs when the service
              terminates because of a signal.
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.4.0</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds398
          </td>
          <td>
            <b>Possible out of order delivery in case of ORDER_BY_SOURCE_TIMESTAMP.</b><br/>
            <i>
              In case of ORDER_BY_SOURCE_TIMESTAMP samples could be delivered out of order.
              <br><br>
              <b>Solution: </b> In case of KEEP_LAST this is now avoided by discarding samples
               that have a timestamp that is older than the lastest consumed sample. Since
               KEEP_ALL is not allowed to discard samples, it can still receive samples out of order.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            Bugzilla#34<br/>
            dds478 / dds2353
          </td>
          <td>
            <b>Susbcribing with an illegal topic name cause core dump</b><br/>
            <i>
              The OMG specification states in Annex A.2 regarding the TOPICNAME that
              a topic name is an identifier for a topic, and is defined as any
              series of characters ?a?, ..., ?z?, ?A?,..., ?Z?, ?0?, ..., ?9?,
              ?-? but may not start with a digit. OpenSplice will not accept - or /.
              <br/><br/>
              <b>Solution: </b>Ensured OpenSplice DDS is compliant with the
              OMG specification and added a better error message where invalid topic
              names are used.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1504
          </td>
          <td>
            <b>Windows builds put dll's in /lib</b><br/>
            <i>
              dll files should be placed in the bin directory.
              <br/><br/>
              <b>Solution: </b> Changed the packaging of the dll files and they now
              appear in the bin directory.</a>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            5218 / 7254 / 7255 <br/>
            dds665 / dds2235 / dds2338 / dds2339
          </td>
          <td>
            <b>Exhaustion of shared memory</b><br/>
            <i>
              When OpenSplice shared memory limit was exceeded then a crash would occur.
              <br/><br/>
              <b>Solution: </b> Additional checking and configuration has been
              added to stop the crash from occurring and also notifying the application
              developer with messages in the info log that shared memory is reaching
              pre-configured limits. <a href="#highlights">See the 5.4 release highlights
              above</a>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            6925<br>
            dds1948 / dds2054
          </td>
          <td>
            <b>Gracefully shutdown OpenSplice</b><br/>
            <i>
              Where OpenSplice has shutdown unexpectedly then it would leave invalid
              processes and temporary files on windows.
              <br/><br/>
              <b>Solution: </b> On startup of OpenSplice, invalid process and temporary
              files are detected and removed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2277
          </td>
          <td>
            <b>Crash in create_datareader on ContentFilteredTopic that was created with incorrect filter</b><br/>
            <i>
              This was caused by an invalid user filter being added.
              <br/><br/>
              <b>Solution: </b>The invalid user filter is now handled correctly and error message reported.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2281
          </td>
          <td>
            <b>The Durability Service ExpiryTime had a maximum value of 20 seconds</b><br/>
            <i>
              <br/><br/>
              <b>Solution: </b>Removed the a maximum expiry time, so it is now unlimited.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7319<br>
            dds2285
          </td>
          <td>
            <b>The dispose_all command leads to a crash of the splice deamon on
            remote nodes where the topic/partition combination is not known.</b><br/>
            <i>
            When Node A issues a dispose_all command for a specific topic/partition
            combination and this dispose all command is received by remote nodes
            where this topic/partition combination is not known, then a crash in
            the splice daemon is observed when the dispose_all command is processed
            and the topic listeners are being retrieved.
              <br/><br/>
              <b>Solution: </b>When the splice daemon processes a dispose_all
              command it received and it has arrived at the point the topic
              listeners need to be received, it will now verify if the
              partition/topic combination is known. If the partition/topic
              combination is not known, it will not try to send a notification to
              the topic listener and thus avoid the crash.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7466<br>
            dds2357
          </td>
          <td>
            <b>DDS and ethernet connection problems on a multi ports computers</b><br/>
            <i>
              In OpenSplice DDSv5.2 when the default Ethernet card is not available
              the first available multicast Ethernet card is selected, previous to 5.2
              it was the first available broadcast address. However, this doesn't allow
              users to block all traffic if the default adapter is not available.
              <br/><br/>
              <b>Solution: </b>Two new configuration options have been added
              OpenSplice/NetworkService/General/NetworkInterfaceAddress and
              OpenSplice/NetworkService/General/NetworkInterfaceAddress[@forced]. For
              OpenSplice/NetworkService/General/NetworkInterfaceAddress[@forced]
              it specifies whether only the selected NetworkInterfaceAddress should
              be used or others can be used too.
              <li>false - Specifies that the NetworkInterfaceAddress is first used
              but when not available another, when available, is used.(default).</li>
              <li>true - Specifies that only the selected NetworkInterfaceAddress
              can be used.</li>
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2404
          </td>
          <td>
            <b>Errors in Ping Pong examples</b><br/>
            <i>
              The issue was caused by the pong implementation doing a "take" of some data,
              and then writing this straight back to ping. The pong was receiving samples
              that were invalid at the end of the run due to the ping's writer implicitly
              unregistering the instances on shutdown (if there are no more samples in
              the datareader for that instance, an invalid sample is generated).
              These invalid samples are meant to be ignored by the user, instead pong was
              forwarding on the samples.
              <br/><br/>
              <b>Solution: </b>Corrected the problem by adding checks of the form
              <br>
                 if(infoList.value[j].valid_data)<br>
              after a take is made and before it is forwarded.

            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2425
          </td>
          <td>
            <b>idlpp error with typedef of an array with struct in a typedef of array of array with struct</b><br/>
            <i>
              <br/><br/>
              <b>Solution: </b>Fixed idlpp to recursively resolve the actual type
              of a typedef to assure typedefs of typedefs are processed correctly
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2426
          </td>
          <td>
            <b>Value of the "MaxBurstSize" configuration of a networkchannel (200KB
               per resolutiontick) causes problems when running typical evaluation
               tests on an out-of-the-box configuration</b><br/>
              <br/><br/>
            <i>
              <b>Solution: </b>Change made so default configuration is "unlimited"
              for all practical networks in the foreseeable future.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            8686<br/>
            dds2541
          </td>
          <td>
            <b>Crash on restart of application or daemon</b><br/>
            <i>
              When using synchronous write, the splicedaemon or the application
              itself could crash when terminating. This was caused by the fact
              that an internal clean-up algorithm sometimes freed an object
              twice causing the reference count of the object ending up to low.
              The crash occurred when the reference count reached 0 and the
              object was accessed after that again.  <br/><br/>
              <b>Solution: </b>Fixed the internal algorithm to prevent double
              frees of the object.
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.3.0p4</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7121/<br/>
            dds2129
          </td>
          <td>
            <b>Queried meta descriptor incorrect</b><br/>
            <i>
              The capability of querying for the XML metadescriptor string
              for a specific application type did not return the correct
              representation in some cases where cyclic dependencies between
              types in modules existed.
              <br/><br/>
              <b>Solution: </b>Fixed the internal algorithm that builds up the
              XML metadescriptor representation.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7373/<br/>
            dds2312
          </td>
          <td>
            <b>Crash in the tuner when using an enum</b><br/>
            <i>
              The Tuner tool internally using a fixed size buffer to store
              a key definition of a Topic. In case a key definition exceeded
              this buffer, the tool crashed.
              <br/><br/>
              <b>Solution: </b>Changed the fixed size buffer in a dynamically
              allocated buffer based on the actual size of the key definition.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7438/<br/>
            dds2333
          </td>
          <td>
            <b>Performance is too slow</b><br/>
            <i>
              The query optimiser failed to optimise queries for key fields due
              to some internal key name changes introduced by the implementation
              of DataReader instance key optimisations. This implied that
              all query read/take actions were linear searches.
              <br/><br/>
              <b>Solution: </b>The DataReader Query constructor has been made
              aware of the name translation and now implements these
              translations during optimisations.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2378
          </td>
          <td>
            <b>MMF-store configuration should not be mandatory</b><br/>
            <i>
              The mapping-address and size configuration parameters for the
              MMF based persistency implementation should be optional,
              reducing the complexity of out-of-the-box configuration.
              <br/><br/>
              <b>Solution: </b>The mapping-address now by default lies directly
              after the mapped database in virtual memory and is by default
              twice the size of the database to make sure all persistent data
              and potentially one backup fit in there.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2417
          </td>
          <td>
            <b>DLRL Java Doc from windows start menu gives incorrect doc</b><br/>
            <i>
              For the Windows platform not all DLRL documentation was in the
              distribution and the link in the start menu did not point to the
              correct page.
              <br/><br/>
              <b>Solution: </b>Added the missing documentation to the distribution
              and updated the link in the start menu.
            </i>
          </td>
        </tr>
       </table>
    </p>
    <p><h3>5.3.0p3</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2362
          </td>
          <td>
            <b>Deadlock possible with shutdown of splice daemon</b><br/>
            <i>
              Clean up code in the splice daemon could become locked due to
              a race condition.
              <br/><br/>
              <b>Solution: </b>Re-factored the clean up process to eliminate
              the race condition.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            5097/<br/>
            dds729
          </td>
          <td>
            <b>Splice daemon may consume 100% CPU.</b><br/>
            <i>
              When using multiple domains on Windows, services and application
              processes sometimes requested access to a domain from the
              wrong splice daemon. This caused unpredictable behaviour in both
              services and user applications.
              <br/><br/>
              <b>Solution: </b>As there is only one splice daemon per domain the
              domain name has been made part of the name of the pipe making the
              pipe name unique. Furthermore, an illegal request from the
              Tuner tool to the splice daemon pipe on initialisation has been
              removed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7162/<br/>
            dds2164
          </td>
          <td>
            <b>OSPL takes a long time to stop.</b><br/>
            <i>
              Update on previous fix to allow handling of 0.0 instead of just 0
              for time argument.
              <br/><br/>
              <b>Solution: </b>Corrected parameter handling.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7319/<br/>
            dds2285
          </td>
          <td>
            <b>Using dispose_all_data can cause the splice daemon to crash</b><br/>
            <i>
              When a remote node calls a dispose on a local topic instance that does not
              exist then splice daemon will crash
              <br/><br/>
              <b>Solution: </b>Check to ensure local topic instance exists and if not
              then queue the dispose request until it does.</b>
            </i>
          </td>
        </tr>
      </table>
    </p>

    <p><h3>5.3.0p2</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7444/<br/>
            dds2384
          </td>
          <td>
            <b>Incorrect memory allocation causing ospl deamon to stop immediately after starting</b><br/>
            <i>
              The implementation of the code to externally monitor OSPL instances
              on local/remote node used strlen incorrectly causing memory corruption.
              This can have the effect of causing the ospl daemon to stop immediately
              after starting.
              <br/><br/>
              <b>Solution: </b>Remove the use of strlen and use MAX_HOST_NAME_LENGTH
              variable.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2180
          </td>
          <td>
            <b>Windows cannot start and stop 2 separate spliceds with separate domains</b><br/>
            <i>
              An error occurred starting 2 separate spliceds and domains on the same
              windows machine. This was because the _ospl_servicePipeName parameter
              is not unique:  When the second spliced is started is uses the same pipe
              name (and as the max instances param is set to 8) CreateNamedPipe fails
              because it has exceeded the max instances.
              <br/><br/>
              <b>Solution: </b>As there is only one splice daemon per domain the domain
              name has been made part of the name of the pipe making the pipe name
              unique.
            </i>
          </td>
        </tr>
      </table>
    </p>

    <p><h3>5.3.0p1</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7444/<br/>
            dds2367
          </td>
          <td>
            <b>Problems with OSPL Log Report Plugin</b><br/>
            <i>
              The initialize and finalize methods of the report plugin were
              being called twice. This was because the report plugin registration
              and unregister had been implemented in 2 different places
              but were actually only needed in 1 place.
              This also caused the report method of the report plugin to be
              called after the finalize method had been called.
              <br/><br/>
              <b>Solution: </b>Changed implementation to only call report plugin
              register and unregister once.
            </i>
          </td>
        </tr>
      </table>
    </p>

    <p><h3>5.3</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            6494<br>
            dds1506
          </td>
          <td>
            <b>Datareaderlistener is still being triggered while the datareader
            and all related objects have already been freed</b><br/>
            <i>
              When a datareader is being deleted at the same time it is being
              triggered asynchronously via on_data_available() then the
              application may crash. This is caused by an incorrect check that
              validates whether or not a listener thread should be terminated.
              <br/><br/>
              <b>Solution: </b>The error in the checking algorithm has been
              repaired.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1629
          </td>
          <td>
            <b>More helpful error message when using Tuner</b><br/>
            <i>
              When using the Tuner, an error message "Supplied URI is not available" would be
              returned, but this could occur if the URI is not available or the
              shared memory segment could not be mapped.
              <br/><br/>
              <b>Solution: </b>The error message has been updated.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2054
          </td>
          <td>
            <b>Gracefully shutdown OpenSplice on machine shutdown</b><br/>
            <i>
              If a machine is shutdown during the operation of OpenSplice, it is possible
              that OpenSplice will not adequately clean up all temporary resource files.  This
              can be particularly an issue on Windows because the shared memory is represented
              by a mapping to a physical file and can cause problems restarting the domain.
              <br/><br/>
              <b>Solution: </b>On Windows, "ospl start" has been improved to check for and remove
              resource files that do not relate to running processes, prior to starting the domain.
              In future releases this will be improved to remove OpenSplice processes that may be
              running but are associated with invalid resources file.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7051<br>
            dds2071
          </td>
          <td>
            <b>-n option added to idlpp to override the suffix for the ORB header file include</b><br/>
            <i>
               -n &lt;include-suffix&gt; <br>
               Overrides the suffix that is used to identify the ORB dependent
               header file (specifying the data model) that needs to be included.
               Normally the name of this include file is derived from the IDL
               file name and followed by an ORB dependent suffix (e.g. 'C.h'
               for ACE-TAO based ORBs).
               This option is only supported in Corba cohabitation mode for C++.
               In all other cases it is simply ignored.<br>
               Example usage: -e .stub.hpp<br>
               (For a file named 'foo.idl' this will include 'foo.stub.hpp'
               instead of 'fooC.h', which is the default expectation for ACE-TAO.)
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2081
          </td>
          <td>
            <b>Issues with compliance of tooling over different platforms</b><br/>
            <i>
              The tooling delivered with OpenSpliceDDS (like mmstat) did
              not have the same command-line options on all supported platforms.
              <br/><br/>
              <b>Solution: </b>The options have been made consistent for all
              supported platforms.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7068<br>
            dds2083
          </td>
          <td>
            <b>Memory leak for arrays</b><br/>
            <i>
              When an array was freed, and thus the references contained within
              that array, the size was incorrectly determined, which caused a
              memory leak as not all references were freed.
              <br/><br/>
              <b>Solution: </b>So now when the collection is an array, the size
              is determined by the maximum size field of its type, which is
              always set, since an array is always fixed length.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2128
          </td>
          <td>
            <b>Wireshark plug-in not compliant anymore</b><br/>
            <i>
              The Wireshark plug-in is no longer showing correct information
              with the updates in the network format.
              <br/><br/>
              <b>Solution: </b>Updated the Wireshark plug-in to correctly
              interpret the newest networking format.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7162<br>
            dds2164
          </td>
          <td>
            <b>OpenSplice takes a long time to stop when using the ospl -f option</b><br/>
            <i>
              OpenSplice at least takes multiple seconds to terminate when
              sending a TERM signal.
              <br/><br/>
              <b>Solution: </b>Setting the configuration of the already
              existing ServiceTerminatePeriod to "0.0" will now be interpreted
              by all OpenSplice services as immediate request to terminate
              without cleaning up. As a result, all services terminate
              immediately and do not clean-up anything, except for the shared
              memory segment that is still destroyed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2228
          </td>
          <td>
            <b>Registering a type compiled with idlpp -j option causes JVM crash</b><br/>
            <i>
              Calling register_type on TypeSupport classes that have been
              generated using the "-j" option made the application crash. This
              was caused by the fact that an internal algorithm did not
              substitute the name of the type with the by idlpp generated
              type name.
              <br/><br/>
              <b>Solution: </b>Extended the internal algorithm to substitute
              the name.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2247
          </td>
          <td>
            <b>Code generated by idlpp (C++) for multidimensional array does
            not compile</b><br/>
            <i>
              The IDL pre-processor did not generate correct code to copy the
              contents of multidimensional arrays.
              <br/><br/>
              <b>Solution: </b>Updated idlpp to correctly handle
              multidimensional arrays.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7272<br>
            dds2254
          </td>
          <td>
            <b>Error message not displayed</b><br/>
            <i>The error message<br/>
            "Description : shmat failed for 1 with errno 22 ()" is unclear.
            <br/><br/>
              <b>Solution: </b>Updated the error message to show the string
              representation of the error between parentheses or show
              "Unknown error" otherwise.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2274
          </td>
          <td>
            <b>Network communication on Windows does not work in case of multiple network partitions</b><br/>
            <i>
              When multiple network partitions were configured for the networking
              service, communication on Windows did not occur due to a bug
              in the algorithm that matches partition-topic combinations to
              a multicast address.
              <br/><br/>
              <b>Solution: </b>The error in the matching algorithm has been
              repaired.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2276
          </td>
          <td>
            <b>Network partition-name conversion to hash results in always the same hash</b><br/>
            <i>
              The networking service calculates a hash value for every
              configured network-partition. Due to an error in the hash
              algorithm the same hash was calculated for all network-partitions.
              <br/><br/>
              <b>Solution: </b>The error in the hashing algorithm has been
              repaired.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2278
          </td>
          <td>
            <b>Not able to view all DDS nodes</b><br/>
            <i>
              When discovery for networking is enabled, the data that is
              published before the other node has been detected is not
              forwarded by the networking service even though it does see the
              information.
              <br/><br/>
              <b>Solution: </b>During the start-up of the networking service,
              it will now initially assume there is a remote node available and
              send the data over the network, before actually starting to
              rely on discovery.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7319<br/>
            dds2285
          </td>
          <td>
            <b>Using dispose_all_data can cause the splice daemon to crash</b><br/>
            <i>
              Sometimes internal transaction messages were accidently stored as
              actual application samples after they were handled.
              <br/><br/>
              <b>Solution: </b>The algorithm now checks whether a message is
              a transaction message and if so, will not store it anymore.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7329<br>
            dds2294
          </td>
          <td>
            <b>IDL Sequences in C#</b><br/>
            <i>
               Generated C# classes for a sequence of structures failed to write
               a sample.
               <br/><br/>
              <b>Solution: </b>The marshallers for sequence of structures was
              incorrect and has now been fixed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7371<br>
            dds2304
          </td>
          <td>
            <b>Memory leak when continually registering and unregistering the same instance of a sample.</b><br/>
            <i>
              Some piece of administration in shared memory was not freed.
              <br/><br/>
              <b>Solution: </b>Made sure the administration is freed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7373<br>
            dds2305
          </td>
          <td>
            <b>mmstat does not display valid values for 64-bit architecture</b><br/>
            <i>
              The mmstat tool was not able to display memory sizes above the
              32-bit boundary, because a 32-bit type was used to store the
              size.
              <br/><br/>
              <b>Solution: </b>Updated the type of the field to be 64-bit
              on 64-bit platforms.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            Bugzilla#34/<br/>
            dds2309
          </td>
          <td>
            <b>Memory growth (leak) in ospl when sending messages with strings in sequences</b><br/>
            <i>
              The memory used by ospl as reported by mmstat grows each time a
              message is sent when the message contains a sequence of strings
              or a sequence of structures that contain strings.<br/>
              The internal algorithm that generically frees data in shared
              memory uses the available meta-data to know how to free the
              data. Due to an error in the meta-data, the algorithm could
              omit freeing a structure, causing memory leakage.
              <br/><br/>
              <b>Solution: </b>Fixed the error in the meta-data for sequences.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2313
          </td>
          <td>
            <b>Application may crash during execution when using sequences</b><br/>
            <i>
              The internal algorithm that generically frees data in shared
              memory uses the available meta-data to know how to free the
              data. Due to an error in the meta-data, the algorithm could
              free a structure in the wrong way, causing the application to
              crash.
              <br/><br/>
              <b>Solution: </b>Fixed the error in the meta-data for sequences.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7444/<br/>
            dds2335
          </td>
          <td>
            <b>Multiple instances with the same key</b><br/>
            <i>
              Character array fields can be marked to be stored as strings
              internally (using the pragma cats). When a sample is written in
              Java, the internal string had rubbish attached to the end of the
              string.

              This was caused by the algorithm that copies samples from heap
              into shared memory since it did not add a '\0' terminator to the
              string in case the source is a character array causing the
              middleware to interpret the string up to the first '\0' in
              memory after the start of the string.
              <br/><br/>
              <b>Solution: </b>Extended the copy algorithm to add a '\0'
              terminator at the end of the string.
            </i>
          </td>
        </tr>
     </table>
    </p>

    <p><h3>5.2.4p2</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
          <td>
            dds2462
          </td>
          <td>
            <b>OpenSplice for Windows CE now uses the CeSetThreadPriority and CeGetThreadPriotiry functions for thread priority administration.</b>  This replaces the usage of the legacy SetThreadPriority and GetThreadPriotiry functions.<br/><br/>  A bug has also been fixed where some threads started within the OpenSplice daemon had the priority value of 0 rather than CE_THREAD_PRIO_256_NORMAL which maps to 251.<br/>
          </td>
        </tr>
      </table>
    </p>

    <p><h3>5.2.1p3</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7444/<br/>
            dds2367
          </td>
          <td>
            <b>Problems with OSPL Log Report Plugin</b><br/>
            <i>
              The initialize and finalize methods of the report plugin were
              being called twice. This was because the report plugin registration
              and unregister had been implemented in 2 different places
              but were actually only needed in 1 place.
              This also caused the report method of the report plugin to be
              called after the finalize method had been called.
              <br/><br/>
              <b>Solution: </b>Changed implementation to only call report plugin
              register and unregister once.
            </i>
          </td>
        </tr>
      </table>
    </p>

    <p><h3>5.2.1p1</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7157/<br/>
            dds2158
          </td>
          <td>
            <b>Bad parameter passing in reportPlugin initialize.</b><br/>
            <i>
             The report plug-in function definitions and calls did not comply
             with API defined in deployment guide<br/><br/>
            <b>Solution: </b>The function definitions have been compliant with
             the deployment guide.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7270/<br/>
            dds2251
          </td>
          <td>
            <b>Unable to publish an InternalFlight.</b><br/>
            <i>
            Java application crashes during the writing of a sample. The issue
            was that a size marker used in creating the Java meta data was of
            type "short", which is too small.<br/><br/>
            <b>Solution: </b>A bug has been fixed in the Java implementation
            of OpenSplice which restricted the size of the meta model of an
            IDL component (as signified by a #pragma keylist) to 2^16 : 65536.
            This has been rectified and the maximum size of an IDL
            component's meta model is now 2^32 : 4294967296.
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.2.1</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7247/<br>
            dds2229
          </td>
          <td>
            <b>The spliced process goes to 100% load</b><br/>
            <i>
            When running on a 64-bit platform, the spliced goes to 100% load
            in some situations when accessing a virtual memory address above
            the 32-bit range, because of a wrong cast being done in an internal
            algorithm.<br/><br/>
            <b>Solution: </b>The wrong cast has been corrected.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7250/<br/>
            dds2237
          </td>
          <td>
            <b>OSPL unable to create a 4GB shared memory segment</b><br/>
            <i>
            When specifying a database size over 2GB in the configuration file,
            OpenSplice could not be started. This was caused by two things:
            <ul>
              <li>The size of the database was casted to a signed integer internally (so max 2GB)</li>
              <li>The default address where it was mapped into the virtual address space of each
              process participating in DDS conflicted with already existing
              things that were mapped into a process</li>
            </ul><br/><br/>
            <b>Solution: </b>The size is now an unsigned long long for 64-bit
            platform to solved the first issue. To solved the second issue, a
            default address of 0x140000000 has been configured for 64bit
            platforms, but the suitability of this value will vary depending on
            the size of the database that is required, and also with the process
            properties at the operating system level. If the address is not
            suitable, the error log file will describe this. On linux the
            "pmap" utility when ran with the "-x" option can be used to view
            the mapping addresses in use by a particular process.  A mapping
            address value is suitable if the addresses that immediately follow
            it (up to the size of the required database) are not in use.
            Refer to the OpenSplice_Deployment guide for details of the
            OpenSplice/Domain/Database/Address attribute.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2243
          </td>
          <td>
            <b>Topic name for Read/Write access QoS policy interpreted as type name</b><br/>
            <i>
            The XML configuration allows for topic access elements
            ('OpenSplice/Domain/TopicAccess') to be defined which determine
            whether reader and/or writers are allowed to be created for a
            specific topic expression (by means of the 'topic_expression'
            attribute). A bug existed in the implementation of this feature
            where the topic expression was compared to the type name instead
            of the topic name. In effect no proper access control could be
            defined for topics.<br/><br/>
            <b>Solution: </b>The implementation has been changed so that it now
            compares the topic expression with the topic name instead of the
            type name.
            </i>
          </td>
        </tr>
      </table>
    </p>

    <p><h3>5.2</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            6488<br>
            dds1513
          </td>
          <td>
            <b>OpenSplice can be configured to allow a single application to operate in multiple domains</b><br/>
          </td>
        </tr>
        <tr>
          <td>
            6457<br>
            dds1542
          </td>
          <td>
            <b>Generation of additional inappropriate files from idlpp</b><br/>
            <i>
              If A.idl depends on B.idl, and A.idl defines a "pragma keylist",
              then we need to apply idlpp on B.idl too so that BSplDcps.h is generated.
              However idlpp will also generate BDcps.idl which only contains
              namespaces and no struct.<br/><br/>
              <b>Solution: </b>idlpp amended to generate only the appropriate files.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1619
          </td>
          <td>
            <b>DDS shall provide a way to dispose all the instances of a topic in one call
             and to notify the receivers in one notification</b><br/>
            <i>See new features in 5.2 above.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1929
          </td>
          <td>
            <b>Dynamic namespaces for durability</b>
            <i>
              <br/><br/>
              <b>Solution: </b>OpenSplice DDS now supports more dynamic environments by
                 introducing dynamic namespaces. With a dynamic namespaces, the durability service
                 can determine at runtime if a previously unknown namespace discovered from another
                 node needs to be maintained and\or aligned locally. For more information see the related
                 documentation.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1958
          </td>
          <td>
            <b>Warning when opensplice is close to exceeding its amount of configured shared memory</b>
            <i>
              <br/><br/>
              <b>Solution: </b>OpenSplice DDS will now print a warning to the ospl-info.log file
              if the available, non fragmented shared memory is below 10% of the total available shared memory size.
              This warning will only be printed once.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2099
          </td>
          <td>
            <b>Process not terminating if several listeners attached to serveral entities</b><br/>
            <i>
              Using a domain participant in combination with a listener caused a deadlock situation
              to occur within OpenSplice DDS in situations where the listener was processing events while the
              DomainParticipant was already being deleted. The deletion operation would claim a mutex and
              perform various clean functions including stopping the listener thread and then waiting for it to
              terminate. Meanwhile the listener thread could be processing some events and require the mutex lock
              in use by the participant delete function.
              <br/><br/>
              <b>Solution: </b> Fix the delete function of the participant to release the mutex
              while waiting for the listener thread to exit and reclaim it once the exit function returned.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7122<br>
            dds2131
          </td>
          <td>
            <b>Unclear error reports when osplconf updates the configuration</b><br/>
            <i>
              Configuration not parsed properly. <br/><br/>
              <b>Solution: </b>Fixed an error in an XPath expression that is used
              internally to parse part of the configuration and improved the warning
              messages that appear in the info-log file.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2145
          </td>
          <td>
            <b>Developers needed to add dcpssacs.dll to the PATH to use C#</b>
            <br><br>
            <b>Solution: </b>For C#, there is now a signed and versioned Assembly called dcpssacsAssembly.dll, created from the
            the dcpssacs.dll module, which is added to the Global Assembly cache. In this release,
            as part of the installation, this is added to the Global Assembly cache.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2154
          </td>
          <td>
            <b>SPLICE_ORB environment variable not set</b><br/>
            <i>
              In order to build the CORBA C++ example you require the SPLICE_ORB to be
              set. This is not done in release.com for Unix systems. <br/><br/>
              <b>Solution: </b>Added the variable to release.com.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7131/
            dds2157
          </td>
          <td>
            <b>OpenSplice release.com loads jar files at the end of CLASSPATH</b><br/><br/>
            <i>
               <b>Solution: </b>script fixed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7157/
            dds2158
          </td>
          <td>
            <b>Incorrect parameter passing in report plugin.</b><br/>
            <i>
               Parameter passing in the Report Plugin intialise function was incorrect.<br><br>
               <b>Solution: </b>Small code error fixed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7156/
            dds2159
          </td>
          <td>
            <b>Missing report configuration in osplconf.</b><br/>
            <i>
               osplconf tool was not up to date with the deployment guide and did not
               allow some of the configuration items to be set.<br><br>
               <b>Solution: </b>Updated the configuration to match the deployment guide.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7158/
            dds2160
          </td>
          <td>
            <b>spliced crashes when adding a report plugin</b><br/><br/>
            <i>
               <b>Solution: </b>Small code error fixed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2163
          </td>
          <td>
            <b>When using the pragma 'cats' in combination with multiple listed fields,
             the IDLP Pre-processor would crash and not generate any code</b><br/>
            <i>There was a bug within the IDL Pre-Processor idlpp which occured
              when the 'cats' pragma directive was being evaluated and incorrectly take 2 fields from a list.
              This caused a null pointer to be retrieved from the list in the next iteration,
              where a valid field was expected, and idl would crash when the pointer was dereferenced.
              <br/><br/>
              <b>Solution: </b> The double take from the list has been removed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2167
          </td>
          <td>
            <b>Example C#Visual Studio Solution and Project files should be valid for both VS2005 and VS2008</b><br/>
            <i>In 5.1, the C# example projects would only support Visual Studio 2008
              <br/><br/>
              <b>Solution: </b> Projects are now created with Visual Studio 2008.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2173
          </td>
         <td>
             <b>Coherent updates</b><br/>
            <i>See new features in 5.2 above.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2188
          </td>
          <td>
            <b>Builtin topic default QoS incorrect in relation to reliability.max_blocking_time</b><br/>
            <i>
              The specification specifies that the max_blocking_time of the reliability QoS should be 100ms.
              Currently it isset to 0ms.
              <br/><br/>
              <b>Solution: </b>Updated code to set QoS to 100ms.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7190/<br>
            dds2192
          </td>
          <td>
            <b>Instances are unregistered on the DataWriter when its liveliness expires</b><br/>
            <i>
              All instances are unregistered on the DataWriter when its
              liveliness expires, but this is wrong behaviour. It causes write
              calls with an instance-handle to return PRECONDITION_NOT_MET
              after liveliness expires.
              <br/><br/>
              <b>Solution: </b>A DataWriter no longer unregisters its instances
              when its liveliness expires. A DataReader does reset the ownership
              of an instance when liveliness of DataWriter expires in case of
              exclusive ownership.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7186/<br>
            dds2204
          </td>
          <td>
            <b>Communication between different subnetworks not supported</b><br/>
            <i>
              To be able to communicate between different subnetworks the
              DontRoute networking service configuration option needs to be set
              to false for all channels including discovery. Even though the
              networking service supports this configuration, the configurator
              tool did not offer this option for discovery. The same goes for
              other send/receive options that are available for channels.
              <br/><br/>
              <b>Solution: </b>The configurator has been extended to support all
              send/receive options for networking discovery as for the channels.
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.1.1</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds2078
          </td>
          <td>
            <b>Disabled factories default QoS settings not returned.</b><br/>
            <i>
              Default Qos settings for factories are not returned if the factory is in
              a disabled state. If the caller did not initialize the Qos parameter
              (assuming get_default_qos would do that), then an uninitialized QoS
              would be returned. <br/><br/>
              <b>Solution: </b>Removed the check for disabled factories, so that they
              are handled like enabled factories.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7104<br>
            dds2108
          </td>
          <td>
            <b>make_hde will not copy host libs for linux cross compile</b><br/>
            <i>
              If the host and target operating systems are the same, in this case Linux,
              but the target architectures are different the make_hde will not copy the host lib's. <br/><br/>
              <b>Solution: </b>Changed the check in the make_hde script.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2133
          </td>
          <td>
            <b>PATH environment variable corrupted by checkconf script on Windows build
            when using Visual Studio 2008</b><br/>
            <i>
              The ospli/bin/checkconf script, which is included by configure,
              is responsible for checking build requirements and prepares the
              environment for building OpenSplice. The part of the script that
              checks the Microsoft toolchain contains an error when Visual Studio 2008
              is detected. It uses 'cygpath -d' (line: 186) to translate a path
              but this returns the windows representation of the path (including c:\).
              The result is then appended to the Unix PATH environment variable,
              which uses ':' as a field seperator. This corrupts the PATH variable
              which causes the build to fail.<br/><br/>
              <b>Solution: </b>Script amended to handle windows paths correctly.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2165
          </td>
          <td>
            <b>Set default QoS behaviour not compliant with the OMG specification.</b><br/>
            <i>The factory operations set_default_xxx_qos() (where xxx represents
            an entity type, i.e. topic, publisher, subscriber, datawriter and datareader)
            do not work according to the DDS spec when their corresponding XXX_QOS_DEFAULT
            label is passed as parameter. According to the DDS specification, the
            set_default_xxx_qos operation should in that case: "The special value
            XXX_QOS_DEFAULT may be passed to this operation to indicate that the
            default QoS should be reset back to the initial values the factory would
            use, that is the values that would be used if the set_default_xxx_qos
            operation had never been called."
            <br><br> In OpenSplice DDS these operations either
            do nothing and return RETCODE_OK (e.g. set_default_publisher_qos),
            or return a RETCODE_BAD_PARAMETER (e.g. set_default_subscriber_qos).<br><br>
            <b>Solution: </b>Updated the functionality to behave as per the specification.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2177
          </td>
          <td>
            <b>PartitionID changed to be byte swapped before being sent out over the network</b><br/>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.1.0p1</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            7053<br/>
            dds2046
          </td>
          <td>
            <b>When an application attach listeners, then it does not terminate and just hangs after the main thread finished.</b><br/>
            <i>
              Java 'hangs' on exit when not all DDS entities have been deleted.<br/><br/>
              <b>Solution: </b>A shutdown hook is now installed on the JVM.
              The shutdown hook is installed during the first successful call on
              the DomainParticipantFactory.get_instance() operation. This
              shutdown hook will ensure all contained entities of the
              DomainParticipantFactory are deleted before the final shutdown
              of the JVM commences. Before this fix the contained entities
              where deleted during/after the final shutdown of the JVM which
              caused various JVM resources to be accessed by OpenSplice while
              they were no longer available.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7141<br/>
            dds2143
          </td>
          <td>
            <b>Code generation with OSPL IDL pre-processor fails for specific key types</b><br/>
            <i>
              The IDL pre-processor rejects usage of character arrays as key
              fields in IDL. This occurs even though the character array has
              been marked to be interpreted as a string internally by the
              middleware via a '#pragma cats' definition. The IDL pre-processor
              fails to recognize the '#pragma cats' definition during key field
              validation if it is located in a different module and/or in an
              included IDL file. Furthermore the IDL pre-processor incorrectly
              validates character arrays when they are used in combination with
              typedefs.<br/><br/>
              <b>Solution: </b>The IDL pre-processor now is able to recognize
              the '#pragma cats' definition regardless of it's location and
              will also correctly resolve any used typedefs in determining
              whether or not a key field is a character array.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7140<br/>
            dds2144
          </td>
          <td>
            <b>TIMEOUT when writing a topic with synchronous reliability activated</b><br/>
            <i>
              When activating the synchronous reliability on DataReaders and
              DataWriters, the write returns an error code 10 (TIMEOUT) even
              with large timeout (5 secs).<br/><br/>
              <b>Solution: </b>A fix has been implemented to prevent synchronous
              writers from blocking on ACKs from non-matching readers (i.e.
              subscribed on other topics).
              This was because when the writer was created, *all* synchronous
              readers were injected into its administration. But as the
              non-matching readers never received messages from this writer,
              they would never acknowledge and the writer would wait
              infinitely (until timeout).
            </i>
          </td>
        </tr>
      </table>
    </p>
    <p><h3>5.1.0</h3>
      <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            4838<br/>
            dds505
          </td>
          <td>
            <b>Shared DataReaders needed for efficiency</b><br/>
            <i>
              Applications need facilities that allow them to share one
              DataReader over multiple processes on the same node. This
              allows reducing the memory footprint on a node significantly in
              case a lot of applications are interested in the same data<br/><br/>
              <b>Solution:</b>A new 'share' QoS policy has been introduced
              in the SubscriberQos and DataReaderQos that allow applications
              to share these entities.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1011
          </td>
          <td>
            <b>Not all .bat files in the 'bin' directory of the release use Windows line endings</b><br/>
            <i>
              Some .bat files in the 'bin' directory of the Windows release use
              UNIX-style line endings.<br/><br/>
              <b>Solution:</b>Changed the line-endings of the .bat files to
              Windows-style line-endings.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            6569<br/>
            dds1541
          </td>
          <td>
            <b>OSPL does not generate default entry of switch of unions in C++</b><br/>
            <i>
             According to the IDL to C++ mapping, the IDL pre-processor
             should generate a default entry for in case no all the possible
             values of the switch are defined as cases and no default case is
             modelled in IDL. Because this is not done, compiling the
             generated code will show warnings.<br/><br/>
              <b>Solution:</b>A default entry is now generated by the IDL
              pre-processor to make sure compiling the generated code does not
              show any warnings.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            6556<br/>
            dds1551
          </td>
          <td>
            <b>User application conflict with cfg_parse operation</b><br/>
            <i>
              <br/>OpenSplice has a 'cfg_parse' function that is also used
              a lot in other products. This leads to a name collision when
              OpenSplice is used in combination with these other products.<br/><br/>
              <b>Solution:</b>The 'cfg_parse' function has been renamed to
              'cfg_parse_ospl' to prevent collisions.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1552
          </td>
          <td>
            <b>Support for abstract domain identification in create_domain_participant</b><br/>
            <i>
              OpenSplice V4 and before only support URI as domain ID<br/><br/>
              <b>Solution:</b>A DomainId consists of a string that represents either a URI to the
               location of the configuration file (e.g. file:///projects/DDS/ospl.xml) or the
               Domain name as specified in the configuration file. The actual value returned is
               dependent of the value used when creating the DomainParticipant, also see the
               DomainParticipantFactory create_participant operation. If a DomainParticipant
               is created using the Domain name then it will also return the Domain name and
               visa-versa when created using a URI then the URI will be returned by this
               operation. The configuration file, identified by the URI, specifies all
               configuration details of the Domain.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1677
          </td>
          <td>
            <b>os_threadCreate failed because of wrong stack size</b><br/>
            <i>
              <br/>If on the system the PTHREAD_STACK_MIN is smaller than
              OS_STACKSIZE_DEFAULT the call to pthread_attr_setstacksize in
              os_threadCreate (POSIX) will fail.<br/><br/>
              <b>Solution:</b>PTHREAD_STACK_MIN is now used instead.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            6815<br/>
            dds1829
          </td>
          <td>
            <b>Persistent data can get lost</b><br/>
            <i>
              <br/>Due to the durability alignment strategy, persistent data can
              get 'lost'. The durability when not master for a name-space sets
              aside the locally stored persistent data set. Then it aligns with
              the master. When during this process, the host is reset
              (actively or power-fail), the persistent data-set may not be
              complete.<br/><br/>
              <b>Solution:</b>The durability service now stores information about
              having a complete set or not on disk. If it detects on re-start that
              the set is not complete, the 'old' set is restored and injected
              instead to at least have a complete set of data.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1836
          </td>
          <td>
            <b>On VxWorks - ospl reports warning sched_getscheduler failed with error 3 in cmsoap service</b><br/>
            <i>
              This occurs because the sched_getscheduler requires a task id in vxworks6.<br/><br/>
              <b>Solution:</b>Properly handle the case when os_procAttrGetClass is called
               by adding a vxworks6.x specific version of os_procAttrGetClass that passes
               the current task id rather than process id to sched_getscheduler
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1844
          </td>
          <td>
            <b>Addition of networking statistics</b><br/>
            <i>
              A large number of statistics for the networking service have been
              added and these are now available in the OpenSplice Tuner. By
              default, statistics are switched off. The enable them, the following
              needs to be added to the configuration file under //OpenSplice/Domain:<br/>
<pre>&lt;Statistics&gt;
  &lt;Category name="networking" enabled="true"/&gt;
&lt;/Statistics&gt;</pre>
            </i>
          </td>
        </tr>        <tr>
          <td>
            dds1847
          </td>
          <td>
            <b>Support multiple installations of OpenSplice DDS on Windows platforms</b><br/>
            <i>
              OpenSplice DDS uses system variables and thus installing a new
              version of OpenSplice will overwrite the variables for the previous
              installation.<br/><br/>
              <b>Solution:</b>OpenSplice does not use system variables anymore.
              A release.bat script is available in the installation directory to
              configure your environment.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            6792<br/>
            dds1865
          </td>
          <td>
            <b>The IDL pre-processor must report unsupported key types</b><br/>
            <i>
              The IDL pre-processor does not report illegal key fields in a
              type when the attributes are there, but the type of the attributes
              is not supported as a key field. Besides that, it also still
              generated code, causing problems with this code only at run-time.<br/><br/>
              <b>Solution:</b>The IDL pre-processor now reports unsupported
              key fields and does not generate any code in that situation.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1894
          </td>
          <td>
            <b>durability: Two nodes select each other as master, blocking alignment</b><br/>
            <i>
              Due to an error in the algorithm that determines the master-ship of
              a durability service, multiple masters can appear, causing the
              alignment of non-volatile data to fail.<br/><br/>
              <b>Solution:</b>The error in determination of the master has been
              repaired.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1899
          </td>
          <td>
            <b>Asymmetric NetworkPartition configuration</b><br/>
            <i>
              Right now networkPartitions are characterized by an ID that's
              determined by the order in which they're defined in the config-file.
              This does NOT allow for asymmetric configuration. <br/>
              <b>Solution:</b>A name-hash is calculated to create an ID that
              allows asymmetric configuration of networkPartitions over nodes.
            </i>
          </td>
        </tr>
         <tr>
          <td>
            6861<br/>
            dds1903
          </td>
          <td>
            <b>Network partition expression more limited than described and needed</b><br/>
            <i>
              <br/>The network partition.topic expression is more limited than
              described in the deployment manual regarding the usage of
              wild-cards ('*').<br/><br/>
              <b>Solution:</b>Wild-cards are now supported on all levels for
              network-partitions.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1914
          </td>
          <td>
            <b>Improve reporting of non-matching topics</b><br/>
            <i>
              Currently when an application creates a topic that already exists
              in the system it will be compared against the existing one and the
              creation will fail if the definition is not equal.

              The error reports that are generated are not useful as they often
              do not report the topic name. It would be very helpful if users
              know which topic creation fails and what the cause is,
              preferable also report conflicting values.<br/><br/>
              <b>Solution:</b>The type name of the topic is now reported when
              the user tries to create a topic with the same name but a
              different type.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            6879<br/>
            dds1921
          </td>
          <td>
            <b>Illegal object reported followed by segmentation faults</b><br/>
            <i>
              <br/>Applications sometimes report detecting an illegal
              object after which they crash. This is caused by an
              inconsistency in the kernel instance administration.<br/><br/>
              <b>Solution:</b>The error in the internal administration of
              instances in the kernel has been corrected.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1926
          </td>
          <td>
            <b>Setting parameters of a query is too expensive</b><br/>
            <i>
              <br/>Setting a parameter on a simple query
              (using only '=' i.c.w. AND) is too expensive and results in
              congestion on the memory manager.<br/><br/>
              <b>Solution:</b>Instead of fully reconstructing a query, only the
              parameters are now changed for simple queries.
            </i>
          </td>
         </tr>
         <tr>
          <td>
            dds1932
          </td>
          <td>
            <b>State the paths of the ospl-info and  ospl-error files immediately after running ospl start</b><br/>
          </td>
         </tr>
         <tr>
          <td>
            6904<br/>
            dds1938
          </td>
          <td>
            <b>Set query parameters should reset the query cache</b><br/>
            <i>
              <br/>Setting the query parameters should reset the query cache
              because the query when executed over the reader database might
              pass samples with the new arguments. This causes the reader not
              to trigger the application when new data arrives and also can
              lead to the situation in which an application cannot read any
              data from the reader, even though there is data.<br/><br/>
              <b>Solution:</b>The cache is now re-evaluated when a query is
              modified and also when historical data is delivered.
            </i>
          </td>
         </tr>
         <tr>
          <td>
            dds1946
          </td>
          <td>
            <b>Corrupted caching instance pipeline</b><br/>
            <i>
              <br/>The instance pipeline in the kernel is formed by caching
              destination instances at source instances. The design supports
              disconnecting sources but disconnecting destination instances is
              poorly implemented. This may lead to corrupted instance caches
              and in some cases temporary memory leakage.<br/><br/>
              <b>Solution:</b>The pipeline implementation has been modified to
              allow disconnecting destination instances also.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1947
          </td>
          <td>
            <b>Default JDK is now Java 6</b><br/>
            <i>
              OpenSplice DDS V5 is compiled with JDK6, but is compatible
              with JDK5 as we use the -source 1.5 flag
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1965
          </td>
          <td>
            <b>Persistent data-store completeness needs to be communicated to late-joining nodes</b><br/>
            <i>
              When nodes are aligned simultaneously, it is possible for them
              to detect whether they did receive a consistent (complete) persistent
              data-set or not. In this scenario, these nodes can take action to
              prevent injection of incomplete persistent data the next time the
              node starts.

              However, for late joining nodes there is no way to detect if a
              currently available persistent set is complete/consistent. Therefore,
              if a system would be restarted, and a previous late joining node
              from a system where incomplete persistent data was injected would
              become master for this set, injection of incomplete data would happen.<br/><br/>

              <b>Solution:</b>Late joining nodes get information about persistent
              data completeness of other nodes.<br/>

            </i>
          </td>
        </tr>
        <tr>
          <td>
           dds1986
          </td>
          <td>
            <b>Problem with persistent topic having exclusive ownership strength</b>
            <p>Because exclusive persistent/transient samples were not stored
             correctly, writers that no longer existed (for example from a
             persistent store) could in some cases prevent new writers from
             writing new data.<br/><br/>
             <b>Solution:</b>Instances from a persistent store are now always
             implicitly unregistered. Modifications have been made to prevent
             storing persistent register/unregister messages, since these are
             now both implicit. Furthermore, the durability service will maintain
             data according to the OwnershipQosPolicy that is set in the
             TopicQos.
            </p>
          </td>
        </tr>
        <tr>
          <td>
            6989<br/>
            dds1988
          </td>
          <td>
            <b>Linux 64 bit crashes when using a shared memory address above the 4GB range</b><br/>
            <i>
              When using a shared memory address which is not aligned on 8192
              bytes, OpenSplice DDS would crash.<br/><br/>
              <b>Solution:</b>Added functionality to print a warning in the info
              log when the configured shared memory address is not aligned on
              8192 bytes on 64-bit platforms. DDS will also automatically
              select the next correctly aligned address and use that instead.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1998
          </td>
          <td>
            <b>Problem with unions in durability in debug mode</b><br/>
            <i>
              Due to an invalid assertion, the durability service crashed in
              debug mode when using specific constructions within a union.<br/><br/>
              <b>Solution:</b>The invalid assertion has been removed.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1999
          </td>
          <td>
            <b>Problem with durability when publishing a union with switch set to a value without corresponding case</b><br/>
            <i>
              Due to an invalid assumption in the serialization routines, the
              durability service is not able to handle unions correctly when
              the switch is set to a value without a corresponding case.<br/><br/>
              <b>Solution:</b>The serialization routines have been updated to
              handle these unions correctly.
            </i>
          </td>
        </tr>
         <tr>
          <td>
            dds2007
          </td>
          <td>
            <b>Durability crashes when tracing is enabled and needs to print '%' character</b><br/>
            <i>
              <br/>The durability service crashes while tracing information when
              there's a % in the path, because 'fprintf' takes it as format.<br/><br/>
              <b>Solution:</b>The information to print using 'fprintf' is done
              using a format with the string as argument instead of directly
              printing the string.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2013
          </td>
          <td>
            <b>idlpp doesn't allow typedef of interface</b><br/>
            <i>
              Even though no code is generated for (typedefs of) interfaces by
              the IDL pre-processor, it should still allow these constructions
              to be modelled in IDL. <br/><br/>
              <b>Solution:</b>The IDL pre-processor has been modified to ignore
              typedefs of interfaces as well.
            </i>
          </td>
        </tr>
         <tr>
          <td>
            7012<br/>
            dds2015
          </td>
          <td>
            <b>idlpp truncates case label in case of enumeration for java</b><br/>
            <i>
              <br/>If the enumeration label inclusive it's scope is larger than
              100 characters, the label truncated to 99 characters.<br/><br/>
              <b>Solution:</b>The length of an enum label is now dynamically
              determined.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds2022
          </td>
          <td>
            <b>cppgen for Windows can not handle multiple #includes unless
            separated by more than a new-line</b><br/>
            <i>
              In cpp (C Pre Processor) this occurs when you do not have a carriage
              return at the end of an included idl files and there is another
              idl file included after it.<br/><br/>
              <b>Solution:</b>The cpp has been modified to handle this situation
              correctly.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            6974/7023<br/>
            dds2025/dds2089
          </td>
          <td>
            <b>CTRL+C in Java has no effect, JVM must be shutdown using KILL -9</b><br/>
            <i>
              <b>Solution:</b>The exit handling in DDS has been tightened by installing
              a shutdown hook to ensure that all the DDS entities are cleaned up and
              therefore processes can terminate.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            6861<br/>
            dds2029
          </td>
          <td>
            <b>u_queryNew accesses unset variable copy</b><br/>
            <i>
              <br/>In the function u_queryNew the variable copy is accessed and
              used to dispose (q_dispose) while it's value has not been set.<br/><br/>
              <b>Solution:</b>The variable is no longer disposed when it has
              not been set.
            </i>
          </td>
        </tr>
        <tr>
          <td>
          dds2043
          </td>
          <td>
            <b>Allow bigger value of InitialDiscoveryPeriod</b>
            <p>The InitialDiscoveryPeriod max value allowed is 10s. More is
            required by customers. <br/><br/>
            <b>Solution:</b>The maximum value for InitialDiscoveryPeriod is now
            set to 60 seconds
            </p>
          </td>
        </tr>
        <tr>
          <td>
            dds2045
          </td>
          <td>
            <b>PolySpace issues</b><br/>
            <i>
              <br/>Static code analysis with PolySpace demonstrates some
              (potential) problems in the code-base.<br/><br/>
              <b>Solution:</b>The detected problems in the code have been repaired.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            7062<br/>
            dds2072
          </td>
          <td>
            <b>Deadlock in Opensplice callstack when calling write() and take()
               at the same time</b><br/>
            <i>
              Due to an error in the internal locking strategy in the OpenSplice
              kernel, an application can get into a deadlock when three threads are
              concurrently operating on the same set of objects.<br/><br/>
              <b>Solution:</b>The error in the internal locking strategy has been
              repaired.
            </i>
          </td>
        </tr>
     </table>
    <h2><a name="issues_api">Fixed Bugs and Changes affecting API</a></h2>
   <p>
       <h3>5.9.0</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
          OSPL1078/<br>10788
          </td>
          <td>
            <b>Support for parallel demarshalling should be available on Java an C++ </b><br/>
            <i>
               Demarshalling data to a language-binding specific format may take considerable
               processing depending on the type of the data. Since demarshalling is done by the
               application thread performing the read/take, demarshalling occurs single-threadedly,
               limiting the throughput that can be achieved.<br>
               <b>Solution:</b> The C++ and Java datareaders have been extended with support for
               demarshalling with multiple threads. The number of threads used can be controlled
               by using the new set_property(String, String) operation on C++ and Java datareaders.
               The property "parallelReadThreadCount" accepts a string representing a positive integer
               (e.g., "4") as value. If the call was successful, successive read/take operations on
               that datareader will use the provided number of threads for the demarshalling step of
               the respective operations.
               <pre>
                  dr.set_property("parallelReadThreadCount", "4");
               </pre>
        </tr>
       </table>
     </p>
   <p>
       <h3>5.5.0</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
          dds2327
          </td>
          <td>
            <b>OpenSplice supports the get_discovered_xxx() APIs</b><br/>
            <i>
               DomainParticipant; get_discovered_participants(), get_discovered_particpant_data(),
               get_discovered_topics() and get_discovered_topic_data() for C, C++ and Java.
          </td>
        </tr>
       </table>
     </p>
   <p>
       <h3>5.4.0</h3>
       <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
          dds2323
          </td>
          <td>
            <b>Implementation of new DataWriter and DataRead API</b><br/>
            <i>
               DataWriter; get_matched_subscriptions(), get_matched_subscription_data()
               and get_publication_matched_status()<br><br>
               DataReader; get_matched_publications(), get_matched_publication_data() and
               get_subscription_matched_status()<br><br>
               DataWriterListener; on_publication_matched()<br><br>
               DataReaderListener; on_subscription_matched()</i>
          </td>
        </tr>
       </table>
     </p>
       <h3>5.3.0</h3>
        <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            dds845
          </td>
          <td>
            <b>DestinationOrderQosPolicy value is not listed in the language specific DCPSPublication topic</b><br/>
            <i>
              The DDS 1.1 specification mistakenly forgot to mention the DestinationOrderQosPolicy
              in the DCPSPublication builtin topic, which should have been there since the policy is marked
              as being RxO. This omission was repaired in the DDS 1.2 specification. <br><br>
              Although the DestinationOrderQospolicy is actually transmitted in the DCPSPublication builtin topic,
              it still misses in the language specific representation for C, C++ and Java.
              <br/><br/>
              <b>Solution: </b>Added the C, C++ and Java representations for DestinationOrderQospolicy.
          </td>
        </tr>
        <tr>
          <td>
            dds2220
          </td>
          <td>
            <b>The get_key_value() method implementation on the dataReader is missing</b><br/>
            <i>
              The DataReader misses the specified get_key_value() method.
              <br/><br/>
              <b>Solution: </b>Implemented the missing get_key_value() method
              on the dataReader.
            </i>
          </td>
        </tr>
       </table>
     </p>
     <p>
       <h3>5.1.0</h3>
        <table width="90%">
        <tr>
          <th width="14%">
            Report ID.
          </th>
          <th width="86%">
            Description
          </th>
        </tr>
        <tr>
          <td>
            GEN_7<br/>
            dds1577
          </td>
          <td>
            <b>Report Plug-In facility</b><br/>
            <i>
              See the release highlights section
            </i>
          </td>
        </tr>
        <tr>
          <td>
            DDS_4<br/>
            dds1578
          </td>
          <td>
            <b>Network level compression</b><br/>
            <i>
              See the release highlights section
            </i>
          </td>
        </tr>
        <tr>
          <td>
            DDS_29<br/>
            dds1617
          </td>
          <td>
            <b>Create a persistent snapshot</b><br/>
            <i>
              The durability service allows an application to request a snapshot of the values of instances of a topic.
              A snapshot consists of a copy of the current persistent data in a new file, the name of which is provided by the application.
            </i>
          </td>
        </tr>
        <tr>
          <td>
            dds1837
          </td>
          <td>
            <b>The C++ API does not support all Quality of Service</b><br/>
            <i>
              The C++ API (sacpp & ccpp) did not support the following QoS;
              <ul>
                 <li>subscriber.share</li>
                 <li>datareader.share</li>
                 <li>datareader.reader_lifespan</li>
                 <li>datareader.subscription_keys</li>
                 <li>datareader.reader_data_lifecycle</li>
                 <li>DataReaderViewQos</li>
                 <li>viewKeyQosPolicy</li>
              </ul><br/>
              <b>Solution:</b>QoS-ses are now implemented
            </i>
          </td>
        </tr>
        <tr>
          <td>
            Bugzilla#32
          </td>
          <td>
            <b>IDL array of arrays generates code that dosn't compile with standalone C++ mapping</b><br/>
            <i>
              <code>idlpp / cppgen</code> bug fixed such that the following IDL now generates compilable code: <code>typedef unsigned short Matrix[1024][1024];</code>
            </i>
          </td>
        </tr>
     </table>
    </p>

    <p>
    <br/>
    <hr>
    <p>
      <a target="_top" href="http://www.prismtech.com">
      <img src="../images/logo_prismtech2.jpg" align="right"
           width="112" height="29" border="0" alt="PrismTech"></a>
      <a href="#top" target="_self">
      <img src="../images/top.gif" width="32"
           height="32" border="0" alt="TOP"></a><br/>
      <a href="#top" target="_self">Top</a>
    </p>
  </body>
</html>
